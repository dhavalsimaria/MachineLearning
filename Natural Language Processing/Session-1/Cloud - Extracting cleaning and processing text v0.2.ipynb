{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edureka/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = \"\"\"Gold is a chemical element with symbol Au (from Latin: aurum) and atomic number 79, making it one of the higher atomic number elements that occur naturally. In its purest form, it is a bright, slightly reddish yellow, dense, soft, malleable, and ductile metal. Chemically, gold is a transition metal and a group 11 element. It is one of the least reactive chemical elements and is solid under standard conditions. Gold often occurs in free elemental (native) form, as nuggets or grains, in rocks, in veins, and in alluvial deposits. It occurs in a solid solution series with the native element silver (as electrum) and also naturally alloyed with copper and palladium. Less commonly, it occurs in minerals as gold compounds, often with tellurium (gold tellurides).\n",
    "\n",
    "Gold is resistant to most acids, though it does dissolve in aqua regia, a mixture of nitric acid and hydrochloric acid, which forms a soluble tetrachloroaurate anion. Gold is insoluble in nitric acid, which dissolves silver and base metals, a property that has long been used to refine gold and to confirm the presence of gold in metallic objects, giving rise to the term acid test. Gold also dissolves in alkaline solutions of cyanide, which are used in mining and electroplating. Gold dissolves in mercury, forming amalgam alloys, but this is not a chemical reaction.\n",
    "\n",
    "A relatively rare element,[5][6] gold is a precious metal that has been used for coinage, jewelry, and other arts throughout recorded history. In the past, a gold standard was often implemented as a monetary policy, but gold coins ceased to be minted as a circulating currency in the 1930s, and the world gold standard was abandoned for a fiat currency system after 1971.\n",
    "\n",
    "A total of 186,700 tonnes of gold exists above ground, as of 2015.[7] The world consumption of new gold produced is about 50% in jewelry, 40% in investments, and 10% in industry.[8] Gold's high malleability, ductility, resistance to corrosion and most other chemical reactions, and conductivity of electricity have led to its continued use in corrosion resistant electrical connectors in all types of computerized devices (its chief industrial use). Gold is also used in infrared shielding, colored-glass production, gold leafing, and tooth restoration. Certain gold salts are still used as anti-inflammatories in medicine. As of 2016, the world's largest gold producer by far was China with 450 tonnes per year\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_word_tokenize = word_tokenize(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gold',\n",
       " 'is',\n",
       " 'a',\n",
       " 'chemical',\n",
       " 'element',\n",
       " 'with',\n",
       " 'symbol',\n",
       " 'Au',\n",
       " '(',\n",
       " 'from',\n",
       " 'Latin',\n",
       " ':',\n",
       " 'aurum',\n",
       " ')',\n",
       " 'and',\n",
       " 'atomic',\n",
       " 'number',\n",
       " '79',\n",
       " ',',\n",
       " 'making',\n",
       " 'it',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'higher',\n",
       " 'atomic',\n",
       " 'number',\n",
       " 'elements',\n",
       " 'that',\n",
       " 'occur',\n",
       " 'naturally',\n",
       " '.',\n",
       " 'In',\n",
       " 'its',\n",
       " 'purest',\n",
       " 'form',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'bright',\n",
       " ',',\n",
       " 'slightly',\n",
       " 'reddish',\n",
       " 'yellow',\n",
       " ',',\n",
       " 'dense',\n",
       " ',',\n",
       " 'soft',\n",
       " ',',\n",
       " 'malleable',\n",
       " ',',\n",
       " 'and',\n",
       " 'ductile',\n",
       " 'metal',\n",
       " '.',\n",
       " 'Chemically',\n",
       " ',',\n",
       " 'gold',\n",
       " 'is',\n",
       " 'a',\n",
       " 'transition',\n",
       " 'metal',\n",
       " 'and',\n",
       " 'a',\n",
       " 'group',\n",
       " '11',\n",
       " 'element',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'least',\n",
       " 'reactive',\n",
       " 'chemical',\n",
       " 'elements',\n",
       " 'and',\n",
       " 'is',\n",
       " 'solid',\n",
       " 'under',\n",
       " 'standard',\n",
       " 'conditions',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'often',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'free',\n",
       " 'elemental',\n",
       " '(',\n",
       " 'native',\n",
       " ')',\n",
       " 'form',\n",
       " ',',\n",
       " 'as',\n",
       " 'nuggets',\n",
       " 'or',\n",
       " 'grains',\n",
       " ',',\n",
       " 'in',\n",
       " 'rocks',\n",
       " ',',\n",
       " 'in',\n",
       " 'veins',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'alluvial',\n",
       " 'deposits',\n",
       " '.',\n",
       " 'It',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'a',\n",
       " 'solid',\n",
       " 'solution',\n",
       " 'series',\n",
       " 'with',\n",
       " 'the',\n",
       " 'native',\n",
       " 'element',\n",
       " 'silver',\n",
       " '(',\n",
       " 'as',\n",
       " 'electrum',\n",
       " ')',\n",
       " 'and',\n",
       " 'also',\n",
       " 'naturally',\n",
       " 'alloyed',\n",
       " 'with',\n",
       " 'copper',\n",
       " 'and',\n",
       " 'palladium',\n",
       " '.',\n",
       " 'Less',\n",
       " 'commonly',\n",
       " ',',\n",
       " 'it',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'minerals',\n",
       " 'as',\n",
       " 'gold',\n",
       " 'compounds',\n",
       " ',',\n",
       " 'often',\n",
       " 'with',\n",
       " 'tellurium',\n",
       " '(',\n",
       " 'gold',\n",
       " 'tellurides',\n",
       " ')',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'is',\n",
       " 'resistant',\n",
       " 'to',\n",
       " 'most',\n",
       " 'acids',\n",
       " ',',\n",
       " 'though',\n",
       " 'it',\n",
       " 'does',\n",
       " 'dissolve',\n",
       " 'in',\n",
       " 'aqua',\n",
       " 'regia',\n",
       " ',',\n",
       " 'a',\n",
       " 'mixture',\n",
       " 'of',\n",
       " 'nitric',\n",
       " 'acid',\n",
       " 'and',\n",
       " 'hydrochloric',\n",
       " 'acid',\n",
       " ',',\n",
       " 'which',\n",
       " 'forms',\n",
       " 'a',\n",
       " 'soluble',\n",
       " 'tetrachloroaurate',\n",
       " 'anion',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'is',\n",
       " 'insoluble',\n",
       " 'in',\n",
       " 'nitric',\n",
       " 'acid',\n",
       " ',',\n",
       " 'which',\n",
       " 'dissolves',\n",
       " 'silver',\n",
       " 'and',\n",
       " 'base',\n",
       " 'metals',\n",
       " ',',\n",
       " 'a',\n",
       " 'property',\n",
       " 'that',\n",
       " 'has',\n",
       " 'long',\n",
       " 'been',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refine',\n",
       " 'gold',\n",
       " 'and',\n",
       " 'to',\n",
       " 'confirm',\n",
       " 'the',\n",
       " 'presence',\n",
       " 'of',\n",
       " 'gold',\n",
       " 'in',\n",
       " 'metallic',\n",
       " 'objects',\n",
       " ',',\n",
       " 'giving',\n",
       " 'rise',\n",
       " 'to',\n",
       " 'the',\n",
       " 'term',\n",
       " 'acid',\n",
       " 'test',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'also',\n",
       " 'dissolves',\n",
       " 'in',\n",
       " 'alkaline',\n",
       " 'solutions',\n",
       " 'of',\n",
       " 'cyanide',\n",
       " ',',\n",
       " 'which',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'mining',\n",
       " 'and',\n",
       " 'electroplating',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'dissolves',\n",
       " 'in',\n",
       " 'mercury',\n",
       " ',',\n",
       " 'forming',\n",
       " 'amalgam',\n",
       " 'alloys',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'chemical',\n",
       " 'reaction',\n",
       " '.',\n",
       " 'A',\n",
       " 'relatively',\n",
       " 'rare',\n",
       " 'element',\n",
       " ',',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'gold',\n",
       " 'is',\n",
       " 'a',\n",
       " 'precious',\n",
       " 'metal',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'used',\n",
       " 'for',\n",
       " 'coinage',\n",
       " ',',\n",
       " 'jewelry',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'arts',\n",
       " 'throughout',\n",
       " 'recorded',\n",
       " 'history',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'past',\n",
       " ',',\n",
       " 'a',\n",
       " 'gold',\n",
       " 'standard',\n",
       " 'was',\n",
       " 'often',\n",
       " 'implemented',\n",
       " 'as',\n",
       " 'a',\n",
       " 'monetary',\n",
       " 'policy',\n",
       " ',',\n",
       " 'but',\n",
       " 'gold',\n",
       " 'coins',\n",
       " 'ceased',\n",
       " 'to',\n",
       " 'be',\n",
       " 'minted',\n",
       " 'as',\n",
       " 'a',\n",
       " 'circulating',\n",
       " 'currency',\n",
       " 'in',\n",
       " 'the',\n",
       " '1930s',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'world',\n",
       " 'gold',\n",
       " 'standard',\n",
       " 'was',\n",
       " 'abandoned',\n",
       " 'for',\n",
       " 'a',\n",
       " 'fiat',\n",
       " 'currency',\n",
       " 'system',\n",
       " 'after',\n",
       " '1971',\n",
       " '.',\n",
       " 'A',\n",
       " 'total',\n",
       " 'of',\n",
       " '186,700',\n",
       " 'tonnes',\n",
       " 'of',\n",
       " 'gold',\n",
       " 'exists',\n",
       " 'above',\n",
       " 'ground',\n",
       " ',',\n",
       " 'as',\n",
       " 'of',\n",
       " '2015',\n",
       " '.',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'The',\n",
       " 'world',\n",
       " 'consumption',\n",
       " 'of',\n",
       " 'new',\n",
       " 'gold',\n",
       " 'produced',\n",
       " 'is',\n",
       " 'about',\n",
       " '50',\n",
       " '%',\n",
       " 'in',\n",
       " 'jewelry',\n",
       " ',',\n",
       " '40',\n",
       " '%',\n",
       " 'in',\n",
       " 'investments',\n",
       " ',',\n",
       " 'and',\n",
       " '10',\n",
       " '%',\n",
       " 'in',\n",
       " 'industry',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " 'Gold',\n",
       " \"'s\",\n",
       " 'high',\n",
       " 'malleability',\n",
       " ',',\n",
       " 'ductility',\n",
       " ',',\n",
       " 'resistance',\n",
       " 'to',\n",
       " 'corrosion',\n",
       " 'and',\n",
       " 'most',\n",
       " 'other',\n",
       " 'chemical',\n",
       " 'reactions',\n",
       " ',',\n",
       " 'and',\n",
       " 'conductivity',\n",
       " 'of',\n",
       " 'electricity',\n",
       " 'have',\n",
       " 'led',\n",
       " 'to',\n",
       " 'its',\n",
       " 'continued',\n",
       " 'use',\n",
       " 'in',\n",
       " 'corrosion',\n",
       " 'resistant',\n",
       " 'electrical',\n",
       " 'connectors',\n",
       " 'in',\n",
       " 'all',\n",
       " 'types',\n",
       " 'of',\n",
       " 'computerized',\n",
       " 'devices',\n",
       " '(',\n",
       " 'its',\n",
       " 'chief',\n",
       " 'industrial',\n",
       " 'use',\n",
       " ')',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'is',\n",
       " 'also',\n",
       " 'used',\n",
       " 'in',\n",
       " 'infrared',\n",
       " 'shielding',\n",
       " ',',\n",
       " 'colored-glass',\n",
       " 'production',\n",
       " ',',\n",
       " 'gold',\n",
       " 'leafing',\n",
       " ',',\n",
       " 'and',\n",
       " 'tooth',\n",
       " 'restoration',\n",
       " '.',\n",
       " 'Certain',\n",
       " 'gold',\n",
       " 'salts',\n",
       " 'are',\n",
       " 'still',\n",
       " 'used',\n",
       " 'as',\n",
       " 'anti-inflammatories',\n",
       " 'in',\n",
       " 'medicine',\n",
       " '.',\n",
       " 'As',\n",
       " 'of',\n",
       " '2016',\n",
       " ',',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'largest',\n",
       " 'gold',\n",
       " 'producer',\n",
       " 'by',\n",
       " 'far',\n",
       " 'was',\n",
       " 'China',\n",
       " 'with',\n",
       " '450',\n",
       " 'tonnes',\n",
       " 'per',\n",
       " 'year']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in gold_word_tokenize:\n",
    "    fdist[word.lower()]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 39, 'gold': 22, 'in': 22, '.': 18, 'and': 17, 'a': 16, 'of': 12, 'is': 11, 'the': 10, 'as': 8, ...})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_top10=fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 39),\n",
       " ('gold', 22),\n",
       " ('in', 22),\n",
       " ('.', 18),\n",
       " ('and', 17),\n",
       " ('a', 16),\n",
       " ('of', 12),\n",
       " ('is', 11),\n",
       " ('the', 10),\n",
       " ('as', 8)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegEx Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize, blankline_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['79',\n",
       " '11',\n",
       " '5',\n",
       " '6',\n",
       " '1930',\n",
       " '1971',\n",
       " '186',\n",
       " '700',\n",
       " '2015',\n",
       " '7',\n",
       " '50',\n",
       " '40',\n",
       " '10',\n",
       " '8',\n",
       " '2016',\n",
       " '450']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(gold,pattern='\\d+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blankline Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_bl_tokenize=blankline_tokenize(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_bl_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gold is a chemical element with symbol Au (from Latin: aurum) and atomic number 79, making it one of the higher atomic number elements that occur naturally. In its purest form, it is a bright, slightly reddish yellow, dense, soft, malleable, and ductile metal. Chemically, gold is a transition metal and a group 11 element. It is one of the least reactive chemical elements and is solid under standard conditions. Gold often occurs in free elemental (native) form, as nuggets or grains, in rocks, in veins, and in alluvial deposits. It occurs in a solid solution series with the native element silver (as electrum) and also naturally alloyed with copper and palladium. Less commonly, it occurs in minerals as gold compounds, often with tellurium (gold tellurides).'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_bl_tokenize[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_sent_tokenize=sent_tokenize(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gold is a chemical element with symbol Au (from Latin: aurum) and atomic number 79, making it one of the higher atomic number elements that occur naturally.',\n",
       " 'In its purest form, it is a bright, slightly reddish yellow, dense, soft, malleable, and ductile metal.',\n",
       " 'Chemically, gold is a transition metal and a group 11 element.',\n",
       " 'It is one of the least reactive chemical elements and is solid under standard conditions.',\n",
       " 'Gold often occurs in free elemental (native) form, as nuggets or grains, in rocks, in veins, and in alluvial deposits.',\n",
       " 'It occurs in a solid solution series with the native element silver (as electrum) and also naturally alloyed with copper and palladium.',\n",
       " 'Less commonly, it occurs in minerals as gold compounds, often with tellurium (gold tellurides).',\n",
       " 'Gold is resistant to most acids, though it does dissolve in aqua regia, a mixture of nitric acid and hydrochloric acid, which forms a soluble tetrachloroaurate anion.',\n",
       " 'Gold is insoluble in nitric acid, which dissolves silver and base metals, a property that has long been used to refine gold and to confirm the presence of gold in metallic objects, giving rise to the term acid test.',\n",
       " 'Gold also dissolves in alkaline solutions of cyanide, which are used in mining and electroplating.',\n",
       " 'Gold dissolves in mercury, forming amalgam alloys, but this is not a chemical reaction.',\n",
       " 'A relatively rare element,[5][6] gold is a precious metal that has been used for coinage, jewelry, and other arts throughout recorded history.',\n",
       " 'In the past, a gold standard was often implemented as a monetary policy, but gold coins ceased to be minted as a circulating currency in the 1930s, and the world gold standard was abandoned for a fiat currency system after 1971.',\n",
       " 'A total of 186,700 tonnes of gold exists above ground, as of 2015.',\n",
       " '[7] The world consumption of new gold produced is about 50% in jewelry, 40% in investments, and 10% in industry.',\n",
       " \"[8] Gold's high malleability, ductility, resistance to corrosion and most other chemical reactions, and conductivity of electricity have led to its continued use in corrosion resistant electrical connectors in all types of computerized devices (its chief industrial use).\",\n",
       " 'Gold is also used in infrared shielding, colored-glass production, gold leafing, and tooth restoration.',\n",
       " 'Certain gold salts are still used as anti-inflammatories in medicine.',\n",
       " \"As of 2016, the world's largest gold producer by far was China with 450 tonnes per year\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"The Mona Lisa is a half length portrait painting by the Italian Renaissance artist Leonardo da Vinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona_lisa_tokens=nltk.word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Mona',\n",
       " 'Lisa',\n",
       " 'is',\n",
       " 'a',\n",
       " 'half',\n",
       " 'length',\n",
       " 'portrait',\n",
       " 'painting',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Italian',\n",
       " 'Renaissance',\n",
       " 'artist',\n",
       " 'Leonardo',\n",
       " 'da',\n",
       " 'Vinci']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mona_lisa_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona_lisa_bigrams=list(nltk.bigrams(mona_lisa_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Mona'),\n",
       " ('Mona', 'Lisa'),\n",
       " ('Lisa', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'half'),\n",
       " ('half', 'length'),\n",
       " ('length', 'portrait'),\n",
       " ('portrait', 'painting'),\n",
       " ('painting', 'by'),\n",
       " ('by', 'the'),\n",
       " ('the', 'Italian'),\n",
       " ('Italian', 'Renaissance'),\n",
       " ('Renaissance', 'artist'),\n",
       " ('artist', 'Leonardo'),\n",
       " ('Leonardo', 'da'),\n",
       " ('da', 'Vinci')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mona_lisa_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona_lisa_trigrams=list(nltk.trigrams(mona_lisa_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Mona', 'Lisa'),\n",
       " ('Mona', 'Lisa', 'is'),\n",
       " ('Lisa', 'is', 'a'),\n",
       " ('is', 'a', 'half'),\n",
       " ('a', 'half', 'length'),\n",
       " ('half', 'length', 'portrait'),\n",
       " ('length', 'portrait', 'painting'),\n",
       " ('portrait', 'painting', 'by'),\n",
       " ('painting', 'by', 'the'),\n",
       " ('by', 'the', 'Italian'),\n",
       " ('the', 'Italian', 'Renaissance'),\n",
       " ('Italian', 'Renaissance', 'artist'),\n",
       " ('Renaissance', 'artist', 'Leonardo'),\n",
       " ('artist', 'Leonardo', 'da'),\n",
       " ('Leonardo', 'da', 'Vinci')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mona_lisa_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Mona', 'Lisa', 'is'),\n",
       " ('Mona', 'Lisa', 'is', 'a'),\n",
       " ('Lisa', 'is', 'a', 'half'),\n",
       " ('is', 'a', 'half', 'length'),\n",
       " ('a', 'half', 'length', 'portrait'),\n",
       " ('half', 'length', 'portrait', 'painting'),\n",
       " ('length', 'portrait', 'painting', 'by'),\n",
       " ('portrait', 'painting', 'by', 'the'),\n",
       " ('painting', 'by', 'the', 'Italian'),\n",
       " ('by', 'the', 'Italian', 'Renaissance'),\n",
       " ('the', 'Italian', 'Renaissance', 'artist'),\n",
       " ('Italian', 'Renaissance', 'artist', 'Leonardo'),\n",
       " ('Renaissance', 'artist', 'Leonardo', 'da'),\n",
       " ('artist', 'Leonardo', 'da', 'Vinci')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mona_lisa_ngrams=list(nltk.ngrams(mona_lisa_tokens, 4))\n",
    "mona_lisa_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=[\"give\",\"giving\",\"given\",\"gave\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like:like\n",
      "liking:like\n",
      "liked:like\n",
      "likes:like\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=[\"like\",\"liking\",\"liked\",\"likes\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval:retriev\n",
      "retrieved:retriev\n",
      "retrieves:retriev\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=[\"retrieval\",\"retrieved\",\"retrieves\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program:program\n",
      "programs:program\n",
      "programer:program\n",
      "programing:program\n",
      "programers:program\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program:program\n",
      "programs:program\n",
      "programer:program\n",
      "programing:program\n",
      "programers:program\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbst=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbst.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbst.stem('having')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program:program\n",
      "programs:program\n",
      "programer:program\n",
      "programing:program\n",
      "programers:program\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemms(word):\n",
    "    print(\"Porter:\"+pst.stem(word))\n",
    "    print(\"Lancaster:\"+lst.stem(word))\n",
    "    print(\"Snowball:\"+sbst.stem(word))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter:fish\n",
      "Lancaster:fish\n",
      "Snowball:fish\n"
     ]
    }
   ],
   "source": [
    "stemms('fishing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter:corpu\n",
      "Lancaster:corp\n",
      "Snowball:corpus\n"
     ]
    }
   ],
   "source": [
    "stemms('corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter:curricula\n",
      "Lancaster:curricul\n",
      "Snowball:curricula\n"
     ]
    }
   ],
   "source": [
    "stemms('curricula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter:curriculum\n",
      "Lancaster:curricul\n",
      "Snowball:curriculum\n"
     ]
    }
   ],
   "source": [
    "stemms('curriculum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/edureka/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curriculum'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize('curricula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program:program\n",
      "programs:program\n",
      "programer:programer\n",
      "programing:programing\n",
      "programers:programers\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford NLP\n",
    "\n",
    "735mb download. This will require good bandwidth. The process will be killed in cloud lab, so try in local system only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "MODELS_DIR = '/home/edureka/2 Extracting, Cleaning and Preprocessing Text'\n",
    "stanfordnlp.download('en', MODELS_DIR) # Download the English models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'F:\\\\All_Prep\\\\NLP Training\\\\Session\\\\2 Extracting cleaning and processing text\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'F:\\\\All_Prep\\\\NLP Training\\\\Session\\\\2 Extracting cleaning and processing text\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'F:\\\\All_Prep\\\\NLP Training\\\\Session\\\\2 Extracting cleaning and processing text\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'batch_size': 3000, 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "<Token index=1;words=[<Word index=1;text=Barack;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=2;words=[<Word index=2;text=Obama;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=3;words=[<Word index=3;text=was;upos=AUX;xpos=VBD;feats=Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin>]>\n",
      "<Token index=4;words=[<Word index=4;text=born;upos=VERB;xpos=VBN;feats=Tense=Past|VerbForm=Part|Voice=Pass>]>\n",
      "<Token index=5;words=[<Word index=5;text=in;upos=ADP;xpos=IN;feats=_>]>\n",
      "<Token index=6;words=[<Word index=6;text=Hawaii;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=7;words=[<Word index=7;text=.;upos=PUNCT;xpos=.;feats=_>]>\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(processors='tokenize,pos', models_dir=MODELS_DIR, treebank='en_ewt', use_gpu=False, pos_batch_size=3000) # Build the pipeline, specify part-of-speech processor's batch size\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\") # Run the pipeline on input text\n",
    "doc.sentences[0].print_tokens() # Look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: A \tlemma: a\n",
      "word: cat \tlemma: cat\n",
      "word: was \tlemma: be\n",
      "word: seen \tlemma: see\n",
      "word: by \tlemma: by\n",
      "word: John \tlemma: John\n",
      "word: in \tlemma: in\n",
      "word: NY \tlemma: NY\n",
      "word: . \tlemma: .\n"
     ]
    }
   ],
   "source": [
    "# import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma',use_gpu=False,models_dir=MODELS_DIR)\n",
    "\n",
    "# doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
    "doc = nlp(\"A cat was seen by John in NY.\")\n",
    "\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy, Gensim, CoreNLP(Java based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/edureka/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 39),\n",
       " ('gold', 22),\n",
       " ('in', 22),\n",
       " ('.', 18),\n",
       " ('and', 17),\n",
       " ('a', 16),\n",
       " ('of', 12),\n",
       " ('is', 11),\n",
       " ('the', 10),\n",
       " ('as', 8)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation=re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in gold_word_tokenize:\n",
    "    word=punctuation.sub(\"\",words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation) #list after removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stop_words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stp_words=stopwords.words('english')\n",
    "stp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in post_punctuation:\n",
    "    words=words.lower()\n",
    "    if words not in stp_words:\n",
    "        post_stop_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist2=FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in post_stop_words:\n",
    "    fdist2[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gold', 22),\n",
       " ('used', 5),\n",
       " ('chemical', 4),\n",
       " ('element', 4),\n",
       " ('acid', 4),\n",
       " ('[', 4),\n",
       " (']', 4),\n",
       " ('metal', 3),\n",
       " ('standard', 3),\n",
       " ('often', 3)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 39),\n",
       " ('gold', 22),\n",
       " ('in', 22),\n",
       " ('.', 18),\n",
       " ('and', 17),\n",
       " ('a', 16),\n",
       " ('of', 12),\n",
       " ('is', 11),\n",
       " ('the', 10),\n",
       " ('as', 8)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Mary is driving a big car.\"\n",
    "sent_tokens = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/edureka/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[('Mary', 'NNP')]\n",
      "[('is', 'VBZ')]\n",
      "[('driving', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('big', 'JJ')]\n",
      "[('car', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'NNP')]\n",
      "[('is', 'VBZ')]\n",
      "[('eating', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('delicious', 'JJ')]\n",
      "[('cake', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sent2 = \"John is eating a delicious cake.\"\n",
    "sent2_tokens = word_tokenize(sent2)\n",
    "for token in sent2_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jim', 'NNP')]\n",
      "[('eats', 'NNS')]\n",
      "[('a', 'DT')]\n",
      "[('banana', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sent3 = \"Jim eats a banana\"\n",
    "sent3_tokens = word_tokenize(sent3)\n",
    "for token in sent3_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jim', ' ', 'eats', ' ', 'a', ' ', 'banana']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "reg_tokenizer = RegexpTokenizer('(?u)\\W+|\\$[\\d\\.]+|\\S+')\n",
    "regex_tokenize = reg_tokenizer.tokenize(sent3)\n",
    "regex_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jim', 'NNP'),\n",
       " (' ', 'NNP'),\n",
       " ('eats', 'VBZ'),\n",
       " (' ', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'NN'),\n",
       " ('banana', 'NN')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tag = nltk.pos_tag(regex_tokenize)\n",
    "regex_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION US/NNP)\n",
      "  President/NNP\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY White/NNP House/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "from nltk import ne_chunk\n",
    "\n",
    "ne_sent = \"The US President stays in the White House.\"\n",
    "\n",
    "ne_tokens = word_tokenize(ne_sent)\n",
    "ne_tags = nltk.pos_tag(ne_tokens)\n",
    "ne_ner = ne_chunk(ne_tags)\n",
    "print(ne_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Apple/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  fruit/NN\n",
      "  and/CC\n",
      "  (PERSON Apple/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  company/NN\n",
      "  's/POS\n",
      "  name/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "ne_sent2 = \"Apple is a fruit and Apple is a company's name.\"\n",
    "\n",
    "print(ne_chunk(nltk.pos_tag(word_tokenize(ne_sent2))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy - POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\tLemma\tPOS\tTag\tDep\tShape\tisAlpha\tisStop\n",
      "Mary\tMary\tPROPN\tNNP\tnsubj\tXxxx\tTrue\tFalse\n",
      "is\tbe\tAUX\tVBZ\taux\txx\tTrue\tTrue\n",
      "driving\tdrive\tVERB\tVBG\tROOT\txxxx\tTrue\tFalse\n",
      "a\ta\tDET\tDT\tdet\tx\tTrue\tTrue\n",
      "big\tbig\tADJ\tJJ\tamod\txxx\tTrue\tFalse\n",
      "car\tcar\tNOUN\tNN\tdobj\txxx\tTrue\tFalse\n",
      ".\t.\tPUNCT\t.\tpunct\t.\tFalse\tFalse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Mary is driving a big car.\")\n",
    "# doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "print(\"Text\\tLemma\\tPOS\\tTag\\tDep\\tShape\\tisAlpha\\tisStop\")\n",
    "for token in doc:\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, \\\n",
    "                                                  token.shape_, token.is_alpha, token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mary', 'NNP')]\n",
      "[('is', 'VBZ')]\n",
      "[('driving', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('big', 'JJ')]\n",
      "[('car', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"da332ffbd38d4d5f8d60178d532bf249-0\" class=\"displacy\" width=\"950\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">driving</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">big</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">car.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-da332ffbd38d4d5f8d60178d532bf249-0-0\" stroke-width=\"2px\" d=\"M70,227.0 C70,77.0 345.0,77.0 345.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-da332ffbd38d4d5f8d60178d532bf249-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,229.0 L62,217.0 78,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-da332ffbd38d4d5f8d60178d532bf249-0-1\" stroke-width=\"2px\" d=\"M220,227.0 C220,152.0 340.0,152.0 340.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-da332ffbd38d4d5f8d60178d532bf249-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M220,229.0 L212,217.0 228,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-da332ffbd38d4d5f8d60178d532bf249-0-2\" stroke-width=\"2px\" d=\"M520,227.0 C520,77.0 795.0,77.0 795.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-da332ffbd38d4d5f8d60178d532bf249-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,229.0 L512,217.0 528,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-da332ffbd38d4d5f8d60178d532bf249-0-3\" stroke-width=\"2px\" d=\"M670,227.0 C670,152.0 790.0,152.0 790.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-da332ffbd38d4d5f8d60178d532bf249-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,229.0 L662,217.0 678,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-da332ffbd38d4d5f8d60178d532bf249-0-4\" stroke-width=\"2px\" d=\"M370,227.0 C370,2.0 800.0,2.0 800.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-da332ffbd38d4d5f8d60178d532bf249-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M800.0,229.0 L808.0,217.0 792.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\",jupyter=True, options={\"word_spacing\":45,\"compact\":False,\"distance\":150})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Thrun started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian 5 14 NORP\n",
      "Google 61 67 ORG\n",
      "2007 71 75 DATE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/edureka/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "file = nltk.corpus.movie_reviews.words('pos/cv033_24444.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in wonder boys michael douglas plays an aged writer \\\\ professor with such lived - in naturalism that i believe it may be his best performance . ever since wall street , douglas has spent the greater part of his career playing variations on the shark in a suit gordon gecko character he personified in the mid - 80 \\' s . in those performances he tended to exaggerate the vehemence of cutthroat businessmen , with much frothing at the mouth while projecting all his bad intentions to the world . you \\' d think such a man would keep his evil wrapped tightly underneath a good - natured veneer , but from gordon gecko to nicholas van orton , douglas played the role straight and out in the open . in wonder boys his performance isn \\' t showy or a tour de force , it \\' s simple yet truthful . he embodies grady , a craggy old writer with a predilection for pot and pink bathrobes . grady instructs a writers workshop while working tirelessly on a follow up to the novel that put him on the map . when we first encounter this curmudgeon in the midst of his workshop , we hear his sardonic narration on the soundtrack as students bombard one of their own with unfair criticisms . grady points out , in his narration , that they only do so out of jealousy . their target is the very writerly named james leer ( played by the always understated tobey maguire ) , a student full of potential and one whom grady develops a mild affection for . leer is the kind of youth who seems to mechanically block out emotions . he speaks in an intellectualized monotone with just a hint of dry wit around the edges . he \\' s portentous and gloomy , as if modeling himself after the great depressed writers , though his act is a little too calculated . he reminds me of the self - imposed outcast film director , jim jarmusch ( dead man , ghost dog ) . whenever i happen to catch jarmusch in an interview i see the man speaking in a toneless manner ( the monotonous drawl supposedly masking depth or contempt for his interviewer ) , exclusively dressed in black , and with his spiked hair dyed snow white . leer is similar , a guy who equates quirks with depth . tobey maguire fits well in the role . with his round , sweet - eerie face he resembles bud cort from harold and maude . but unlike cort , maguire is easier to warm up to ; he \\' s a messed up kid reaching for artistic credibility . katie holmes plays hannah , a beautiful , talented writing student just itching to get in grady \\' s pants . this is a plot line i had trouble with . douglas , in his old age , is beginning to resemble jerry springer , a man who has actually paid for sex on numerous documented occasions . at first i found it extremely difficult to believe that someone as beautiful as hannah would desire grady ( maybe it \\' s because i \\' m jealous , and wish holmes was throwing herself at me , after all i may just be a lowly internet critic but at least i still have all my teeth ) , then i think of douglas \\' s real life companion , the breathtaking catherine zeta jones . seeing those two together looks a lot like a kidnapping . suddenly my mind has shifted from the task at hand ( that being reviewing this completely wonderful movie ) and i \\' m pontificating on why the hell jones would desire douglas . there is a movie in there somewhere . grady , rather chivalrously if you ask me , resists the charms of hannah for sara gaskell ( a droll frances mcdormand ) , who is his age , but also married to another professor . okay , maybe not so chivalrous . there is a great line in the film spoken by douglas about sara where he says , \" she was a junkie for the printed word . lucky for me i manufactured her drug of choice \" . robert downy j . r plays a bisexual editor who makes his entrance with a towering transvestite on his arm . downy has mastered the gleefully dry hyper articulate wit of many a hipster intellectual . he \\' s arrogant but completely likeable in his utter arrogance . the actor is perfectly cast here , and remains a joyous movie presence somewhere between a typical tom hanksian comic leading man and edgy character actor . i wish wonder boys had more of him . searching for a plot among the elements of wonder boys would be pointless , for it meanders through its running time , but that \\' s part of its charm . and maybe i \\' m a bit biased towards the film because it takes place in a haven of literary academia , a place i \\' m greatly fond of , and a place rarely explored in american cinema . everyone has a sub - genre ( be it war films , westerns , dance movies ) that they happen to be privy to . i \\' m privy to films about literary types i . e . those individuals enthralled by the written word , and if you are not so inclined it may be wise to knock my above grade down about half a notch . the direction by curtis hanson is more akin to a european film with its leisurely pace and situations that grow from the characters , rather than generic mapped out story points . sometimes the dialogue is too clever , but that \\' s a problem i wish i found with films more often . another minor quibble is that early on the film seems a bit too introverted , like its characters , but as the story progresses it begins to open up . for me wonder boys works as subtle drama because of its insight into artistic types , and as a low - key comedy for its chuckle - worthy throwaway gags . the gags are like those in the great robert altman ( m * a * s * h , the long goodbye ) movies , where jokes exist as asides on the fringes , like jokes in life often do . the broader comedy such as the killing of a blind dog , and incessant smoking of marijuana isn \\' t ineffective but not nearly as memorable as the little things . curtis hanson , who before his last film , la confidential , toiled about with exploitation fare like losin \\' it ( an early tom cruise sex comedy ) and the hand the rocks the cradle , has graduated to more meaningful films . he directs wonder boys in an appropriately dour style , the comedy coming from the false gloom his characters put up . the morose crooning of leonard cohen would seem an odd song for the background of any party , but in a wonder boys party , it fits . the film is like a piece of literature put up on the big screen . it \\' s the cinematic equivalent to a good read , novelistic in its approach with themes rarely found in american movies . many will find it slight , but i found much to savor among its subtleties .'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist5 = FreqDist()\n",
    "for word in file:\n",
    "    fdist5[word.lower()]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 60),\n",
       " ('.', 54),\n",
       " ('the', 54),\n",
       " ('a', 46),\n",
       " ('in', 27),\n",
       " ('of', 24),\n",
       " ('to', 21),\n",
       " (\"'\", 20),\n",
       " ('i', 19),\n",
       " ('his', 19)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist5.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Remove the stop words and find out the most common words occuring in the list?\n",
    "2. Apply stemming and Lemmatization. Does the frequency of most common words change? \n",
    "3. Try POS and NER, both from NLTK and Spacy. Do you notice any differnce?\n",
    "4. How accurately both models are able to find out the names? What do you think the reason for such output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
