{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End-Course Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqgGbWQwLLbjFRVqBrSVco",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhavalsimaria/MachineLearning/blob/master/NITW/DL%20%26%20AI/End_Course_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSDU4HpPcpsv",
        "colab_type": "code",
        "outputId": "15d26dee-b6af-4af6-9fde-4bfc4d47810e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Input, Conv2D, Flatten, Reshape, Activation, MaxPooling2D\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZSZgh98BL3-",
        "colab_type": "code",
        "outputId": "82f586ee-d7d3-49a2-f8b0-229cd6a555b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#Question: 1.A\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuROYQRmBv7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question: 1.B\n",
        "# Change the data type to float32 and normalize\n",
        "x_train_normalized = x_train.astype('float32')/255\n",
        "x_test_normalized = x_test.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2jwPlRHCHoM",
        "colab_type": "code",
        "outputId": "498c8020-ed12-4942-dee6-47d9562aa6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG9BeK1gCPU6",
        "colab_type": "code",
        "outputId": "3f5b20c8-9252-473e-e614-62ffe387877b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train_normalized[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.05098039, 0.28627452, 0.        , 0.        , 0.00392157,\n",
              "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.        , 0.14117648,\n",
              "        0.53333336, 0.49803922, 0.24313726, 0.21176471, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568628,\n",
              "        0.        , 0.        , 0.01176471],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "        0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
              "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04705882, 0.03921569, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.60784316,\n",
              "        0.9254902 , 0.8117647 , 0.69803923, 0.41960785, 0.6117647 ,\n",
              "        0.6313726 , 0.42745098, 0.2509804 , 0.09019608, 0.3019608 ,\n",
              "        0.50980395, 0.28235295, 0.05882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.27058825, 0.8117647 ,\n",
              "        0.8745098 , 0.85490197, 0.84705883, 0.84705883, 0.6392157 ,\n",
              "        0.49803922, 0.4745098 , 0.47843137, 0.57254905, 0.5529412 ,\n",
              "        0.34509805, 0.6745098 , 0.25882354],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.        , 0.78431374, 0.9098039 ,\n",
              "        0.9098039 , 0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 ,\n",
              "        0.84313726, 0.8352941 , 0.6431373 , 0.49803922, 0.48235294,\n",
              "        0.76862746, 0.8980392 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.7176471 , 0.88235295,\n",
              "        0.84705883, 0.8745098 , 0.89411765, 0.92156863, 0.8901961 ,\n",
              "        0.8784314 , 0.87058824, 0.8784314 , 0.8666667 , 0.8745098 ,\n",
              "        0.9607843 , 0.6784314 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
              "        0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
              "        0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
              "        0.9529412 , 0.7921569 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.04705882, 0.85882354, 0.8627451 ,\n",
              "        0.83137256, 0.85490197, 0.7529412 , 0.6627451 , 0.8901961 ,\n",
              "        0.8156863 , 0.85490197, 0.8784314 , 0.83137256, 0.8862745 ,\n",
              "        0.77254903, 0.81960785, 0.20392157],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.        , 0.3882353 , 0.95686275, 0.87058824,\n",
              "        0.8627451 , 0.85490197, 0.79607844, 0.7764706 , 0.8666667 ,\n",
              "        0.84313726, 0.8352941 , 0.87058824, 0.8627451 , 0.9607843 ,\n",
              "        0.46666667, 0.654902  , 0.21960784],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
              "        0.        , 0.        , 0.21568628, 0.9254902 , 0.89411765,\n",
              "        0.9019608 , 0.89411765, 0.9411765 , 0.9098039 , 0.8352941 ,\n",
              "        0.85490197, 0.8745098 , 0.91764706, 0.8509804 , 0.8509804 ,\n",
              "        0.81960785, 0.36078432, 0.        ],\n",
              "       [0.        , 0.        , 0.00392157, 0.01568628, 0.02352941,\n",
              "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.92941177, 0.8862745 , 0.8509804 ,\n",
              "        0.8745098 , 0.87058824, 0.85882354, 0.87058824, 0.8666667 ,\n",
              "        0.84705883, 0.8745098 , 0.8980392 , 0.84313726, 0.85490197,\n",
              "        1.        , 0.3019608 , 0.        ],\n",
              "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
              "        0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
              "        0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
              "        0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
              "        0.95686275, 0.62352943, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.17254902, 0.32156864, 0.41960785, 0.7411765 , 0.89411765,\n",
              "        0.8627451 , 0.87058824, 0.8509804 , 0.8862745 , 0.78431374,\n",
              "        0.8039216 , 0.827451  , 0.9019608 , 0.8784314 , 0.91764706,\n",
              "        0.6901961 , 0.7372549 , 0.98039216, 0.972549  , 0.9137255 ,\n",
              "        0.93333334, 0.84313726, 0.        ],\n",
              "       [0.        , 0.22352941, 0.73333335, 0.8156863 , 0.8784314 ,\n",
              "        0.8666667 , 0.8784314 , 0.8156863 , 0.8       , 0.8392157 ,\n",
              "        0.8156863 , 0.81960785, 0.78431374, 0.62352943, 0.9607843 ,\n",
              "        0.75686276, 0.80784315, 0.8745098 , 1.        , 1.        ,\n",
              "        0.8666667 , 0.91764706, 0.8666667 , 0.827451  , 0.8627451 ,\n",
              "        0.9098039 , 0.9647059 , 0.        ],\n",
              "       [0.01176471, 0.7921569 , 0.89411765, 0.8784314 , 0.8666667 ,\n",
              "        0.827451  , 0.827451  , 0.8392157 , 0.8039216 , 0.8039216 ,\n",
              "        0.8039216 , 0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 ,\n",
              "        1.        , 0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 ,\n",
              "        0.7490196 , 0.8235294 , 0.8       , 0.81960785, 0.87058824,\n",
              "        0.89411765, 0.88235295, 0.        ],\n",
              "       [0.38431373, 0.9137255 , 0.7764706 , 0.8235294 , 0.87058824,\n",
              "        0.8980392 , 0.8980392 , 0.91764706, 0.9764706 , 0.8627451 ,\n",
              "        0.7607843 , 0.84313726, 0.8509804 , 0.94509804, 0.25490198,\n",
              "        0.28627452, 0.41568628, 0.45882353, 0.65882355, 0.85882354,\n",
              "        0.8666667 , 0.84313726, 0.8509804 , 0.8745098 , 0.8745098 ,\n",
              "        0.8784314 , 0.8980392 , 0.11372549],\n",
              "       [0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
              "        0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
              "        0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
              "        0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
              "        0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
              "        0.8666667 , 0.9019608 , 0.2627451 ],\n",
              "       [0.1882353 , 0.79607844, 0.7176471 , 0.7607843 , 0.8352941 ,\n",
              "        0.77254903, 0.7254902 , 0.74509805, 0.7607843 , 0.7529412 ,\n",
              "        0.7921569 , 0.8392157 , 0.85882354, 0.8666667 , 0.8627451 ,\n",
              "        0.9254902 , 0.88235295, 0.84705883, 0.78039217, 0.80784315,\n",
              "        0.7294118 , 0.70980394, 0.69411767, 0.6745098 , 0.70980394,\n",
              "        0.8039216 , 0.80784315, 0.4509804 ],\n",
              "       [0.        , 0.47843137, 0.85882354, 0.75686276, 0.7019608 ,\n",
              "        0.67058825, 0.7176471 , 0.76862746, 0.8       , 0.8235294 ,\n",
              "        0.8352941 , 0.8117647 , 0.827451  , 0.8235294 , 0.78431374,\n",
              "        0.76862746, 0.7607843 , 0.7490196 , 0.7647059 , 0.7490196 ,\n",
              "        0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 , 0.654902  ,\n",
              "        0.69411767, 0.8235294 , 0.36078432],\n",
              "       [0.        , 0.        , 0.2901961 , 0.7411765 , 0.83137256,\n",
              "        0.7490196 , 0.6862745 , 0.6745098 , 0.6862745 , 0.70980394,\n",
              "        0.7254902 , 0.7372549 , 0.7411765 , 0.7372549 , 0.75686276,\n",
              "        0.7764706 , 0.8       , 0.81960785, 0.8235294 , 0.8235294 ,\n",
              "        0.827451  , 0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 ,\n",
              "        0.84705883, 0.6666667 , 0.        ],\n",
              "       [0.00784314, 0.        , 0.        , 0.        , 0.25882354,\n",
              "        0.78431374, 0.87058824, 0.92941177, 0.9372549 , 0.9490196 ,\n",
              "        0.9647059 , 0.9529412 , 0.95686275, 0.8666667 , 0.8627451 ,\n",
              "        0.75686276, 0.7490196 , 0.7019608 , 0.7137255 , 0.7137255 ,\n",
              "        0.70980394, 0.6901961 , 0.6509804 , 0.65882355, 0.3882353 ,\n",
              "        0.22745098, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "        0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajm9xvUrCXsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question: 2\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMgRowyEYl_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "c14c0ce4-b718-4fe7-b4c7-3fb74e3879c8"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train_normalized[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAJvVl0rYoUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question: 3\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKJricpXZZF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19ffe01d-de9b-403d-ed68-e198d1d86730"
      },
      "source": [
        "print('Train image before reshaping: ', x_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train image before reshaping:  (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2yzHnCZZ-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the input images\n",
        "x_train_reshaped = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test_reshaped = x_test.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3HUU-N6Ziel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28602494-cfe7-4c13-9081-19e3e0ff7921"
      },
      "source": [
        "print('Train image after reshaping: ', x_train_reshaped.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train image after reshaping:  (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZhcK5dQZnnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 4.A\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=(1,1),\n",
        "          input_shape= [28,28,1]))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY27zG8Us73U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_4a = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R20kkYvltOyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "6dbf359c-d8e7-4e9c-8197-d53ec3eac65b"
      },
      "source": [
        "model_4a.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 804,554\n",
            "Trainable params: 804,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uosb-trii_0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 4.B\n",
        "model_4a.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRb-HBMjKuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a5fd76f-1465-4250-8b7b-bc7366eacbb1"
      },
      "source": [
        "# Question 4.C\n",
        "model_4a.fit(x_train_reshaped, y_train, validation_data=(x_test_reshaped, y_test), batch_size=1000, epochs=30)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 38.3950 - accuracy: 0.6807 - val_loss: 4.1599 - val_accuracy: 0.8200\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.2431 - accuracy: 0.8481 - val_loss: 1.7496 - val_accuracy: 0.8429\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.1965 - accuracy: 0.8667 - val_loss: 1.1739 - val_accuracy: 0.8584\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.8289 - accuracy: 0.8759 - val_loss: 1.0034 - val_accuracy: 0.8597\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.6744 - accuracy: 0.8830 - val_loss: 0.9056 - val_accuracy: 0.8599\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.5175 - accuracy: 0.8938 - val_loss: 0.8440 - val_accuracy: 0.8623\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.4428 - accuracy: 0.8994 - val_loss: 0.7620 - val_accuracy: 0.8690\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3697 - accuracy: 0.9064 - val_loss: 0.6994 - val_accuracy: 0.8767\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3235 - accuracy: 0.9128 - val_loss: 0.7052 - val_accuracy: 0.8723\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2966 - accuracy: 0.9165 - val_loss: 0.7715 - val_accuracy: 0.8661\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2753 - accuracy: 0.9205 - val_loss: 0.7211 - val_accuracy: 0.8670\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2598 - accuracy: 0.9234 - val_loss: 0.6380 - val_accuracy: 0.8774\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2399 - accuracy: 0.9281 - val_loss: 0.6252 - val_accuracy: 0.8782\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2383 - accuracy: 0.9286 - val_loss: 0.6700 - val_accuracy: 0.8801\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2256 - accuracy: 0.9304 - val_loss: 0.6344 - val_accuracy: 0.8789\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2138 - accuracy: 0.9332 - val_loss: 0.6276 - val_accuracy: 0.8795\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1973 - accuracy: 0.9368 - val_loss: 0.6290 - val_accuracy: 0.8790\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1848 - accuracy: 0.9402 - val_loss: 0.6066 - val_accuracy: 0.8843\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1803 - accuracy: 0.9417 - val_loss: 0.6208 - val_accuracy: 0.8827\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1757 - accuracy: 0.9432 - val_loss: 0.6363 - val_accuracy: 0.8807\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1636 - accuracy: 0.9451 - val_loss: 0.6056 - val_accuracy: 0.8813\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1629 - accuracy: 0.9459 - val_loss: 0.6167 - val_accuracy: 0.8846\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1576 - accuracy: 0.9465 - val_loss: 0.6142 - val_accuracy: 0.8810\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1442 - accuracy: 0.9509 - val_loss: 0.6308 - val_accuracy: 0.8843\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1605 - accuracy: 0.9456 - val_loss: 0.6176 - val_accuracy: 0.8863\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1486 - accuracy: 0.9493 - val_loss: 0.6184 - val_accuracy: 0.8842\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1495 - accuracy: 0.9490 - val_loss: 0.6690 - val_accuracy: 0.8795\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1464 - accuracy: 0.9502 - val_loss: 0.6270 - val_accuracy: 0.8817\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1440 - accuracy: 0.9512 - val_loss: 0.6215 - val_accuracy: 0.8876\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1397 - accuracy: 0.9533 - val_loss: 0.6399 - val_accuracy: 0.8822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5aa076c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0SwQVg1mBW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 5\n",
        "model_5 = build_model()\n",
        "model_5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2g5u4NcmPKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "4c7d7c92-aa7c-45f4-ec43-ccbe415cabc6"
      },
      "source": [
        "model_5.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 804,554\n",
            "Trainable params: 804,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GbFWb-PmThc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert y_train and y_test to categorical data\n",
        "num_classes = 10\n",
        "encoded_y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "encoded_y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqemeWtQnDp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ba8e23d-63a5-4d7e-9219-f4dba63ac5cc"
      },
      "source": [
        "model_5.fit(x_train_reshaped, encoded_y_train, validation_data=(x_test_reshaped, encoded_y_test), batch_size=1000, epochs=30)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 56.6737 - accuracy: 0.6898 - val_loss: 5.3260 - val_accuracy: 0.8233\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.7790 - accuracy: 0.8510 - val_loss: 2.0233 - val_accuracy: 0.8374\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 1.3289 - accuracy: 0.8643 - val_loss: 1.2899 - val_accuracy: 0.8593\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.9011 - accuracy: 0.8760 - val_loss: 1.1527 - val_accuracy: 0.8538\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.7508 - accuracy: 0.8794 - val_loss: 1.1449 - val_accuracy: 0.8522\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.6752 - accuracy: 0.8845 - val_loss: 0.8747 - val_accuracy: 0.8724\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.5280 - accuracy: 0.8947 - val_loss: 0.8778 - val_accuracy: 0.8678\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.5585 - accuracy: 0.8907 - val_loss: 0.8596 - val_accuracy: 0.8697\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4318 - accuracy: 0.9037 - val_loss: 0.7573 - val_accuracy: 0.8710\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4463 - accuracy: 0.9010 - val_loss: 0.7556 - val_accuracy: 0.8798\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3525 - accuracy: 0.9130 - val_loss: 0.6912 - val_accuracy: 0.8776\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3146 - accuracy: 0.9171 - val_loss: 0.6601 - val_accuracy: 0.8823\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3080 - accuracy: 0.9182 - val_loss: 0.6999 - val_accuracy: 0.8819\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2837 - accuracy: 0.9216 - val_loss: 0.6433 - val_accuracy: 0.8837\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2348 - accuracy: 0.9305 - val_loss: 0.6478 - val_accuracy: 0.8812\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2210 - accuracy: 0.9324 - val_loss: 0.7316 - val_accuracy: 0.8674\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2468 - accuracy: 0.9273 - val_loss: 0.8538 - val_accuracy: 0.8526\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2091 - accuracy: 0.9361 - val_loss: 0.6112 - val_accuracy: 0.8859\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2490 - accuracy: 0.9287 - val_loss: 0.6296 - val_accuracy: 0.8880\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1832 - accuracy: 0.9412 - val_loss: 0.6010 - val_accuracy: 0.8878\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1738 - accuracy: 0.9429 - val_loss: 0.6156 - val_accuracy: 0.8868\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2003 - accuracy: 0.9377 - val_loss: 0.7174 - val_accuracy: 0.8721\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1684 - accuracy: 0.9449 - val_loss: 0.6151 - val_accuracy: 0.8847\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1732 - accuracy: 0.9431 - val_loss: 0.6140 - val_accuracy: 0.8821\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2093 - accuracy: 0.9365 - val_loss: 0.7140 - val_accuracy: 0.8727\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1709 - accuracy: 0.9449 - val_loss: 0.6712 - val_accuracy: 0.8773\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1557 - accuracy: 0.9474 - val_loss: 0.6283 - val_accuracy: 0.8863\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1548 - accuracy: 0.9482 - val_loss: 0.6927 - val_accuracy: 0.8750\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1552 - accuracy: 0.9473 - val_loss: 0.6357 - val_accuracy: 0.8842\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1462 - accuracy: 0.9506 - val_loss: 0.6447 - val_accuracy: 0.8840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5aa0549940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBqkF9nho3uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 6.A\n",
        "model_5.save_weights(\"my_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgR7tKP9pbAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee00d807-be72-4cdf-aa33-ee0baf932701"
      },
      "source": [
        "# Question 6.B\n",
        "restored_model = build_model()\n",
        "restored_model.load_weights(\"my_model.h5\")\n",
        "restored_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "accuracy_for_restored_model = restored_model.evaluate(x_test_reshaped, encoded_y_test, verbose=0)\n",
        "print(\"Restored model, accuracy: \", np.round(accuracy_for_restored_model[1]*100, 2), \"%\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored model, accuracy:  88.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh3NGXF-y0kW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "02b17769-271f-4b16-8afa-b8bccdb71471"
      },
      "source": [
        "# Question 7\n",
        "model_y_pred = restored_model.predict(x_test_reshaped)\n",
        "model_y_pred = np.argmax(model_y_pred, axis=1)\n",
        "y_true = np.argmax(encoded_y_test,axis=1)\n",
        "print(metrics.classification_report(y_true, model_y_pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82      1000\n",
            "           1       0.98      0.97      0.98      1000\n",
            "           2       0.88      0.69      0.77      1000\n",
            "           3       0.89      0.89      0.89      1000\n",
            "           4       0.78      0.86      0.82      1000\n",
            "           5       0.96      0.97      0.97      1000\n",
            "           6       0.66      0.78      0.72      1000\n",
            "           7       0.95      0.95      0.95      1000\n",
            "           8       0.97      0.96      0.97      1000\n",
            "           9       0.96      0.96      0.96      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.89      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SVGdj-Iz2X6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87c68bc6-e90c-4625-9479-675ac399adc0"
      },
      "source": [
        "# Question 8\n",
        "miscalculations = np.size(np.where(y_true!=model_y_pred)[0])\n",
        "print(miscalculations)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AOw7KpQ16Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 9\n",
        "exp_epoch_list = [10, 30, 50]\n",
        "exp_batch_size_list = [500, 1000, 5000]\n",
        "exp_optimizer_list = ['adam', 'rmsprop', 'sgd']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7mt05Y2W3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7e1e1c2-3fab-4d26-df47-84b3629f83fd"
      },
      "source": [
        "exp_dict = {}\n",
        "for exp_optimizer in exp_optimizer_list:\n",
        "  for exp_epoch in exp_epoch_list:\n",
        "    for exp_batch_size in exp_batch_size_list:\n",
        "      model_5 = build_model()\n",
        "      model_5.compile(loss='categorical_crossentropy', optimizer=exp_optimizer, metrics=['accuracy'])\n",
        "      model_5.fit(x_train_reshaped, encoded_y_train, validation_data=(x_test_reshaped, encoded_y_test), batch_size=exp_batch_size, epochs=exp_epoch)\n",
        "      accuracy_for_restored_model = np.round(restored_model.evaluate(x_test_reshaped, encoded_y_test, verbose=0)[1], 4)\n",
        "      dict_key = exp_optimizer+str(exp_epoch)+str(exp_batch_size);\n",
        "      print(dict_key, \": \", accuracy_for_restored_model)\n",
        "      exp_dict[dict_key] = accuracy_for_restored_model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 14.5358 - accuracy: 0.7865 - val_loss: 1.6848 - val_accuracy: 0.8569\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.3192 - accuracy: 0.8599 - val_loss: 1.0896 - val_accuracy: 0.8656\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.7343 - accuracy: 0.8808 - val_loss: 0.8233 - val_accuracy: 0.8693\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.5029 - accuracy: 0.8942 - val_loss: 0.8354 - val_accuracy: 0.8575\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.3894 - accuracy: 0.9048 - val_loss: 0.6259 - val_accuracy: 0.8769\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2989 - accuracy: 0.9162 - val_loss: 0.6091 - val_accuracy: 0.8733\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.2836 - accuracy: 0.9181 - val_loss: 0.6388 - val_accuracy: 0.8685\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2569 - accuracy: 0.9231 - val_loss: 0.5639 - val_accuracy: 0.8789\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2306 - accuracy: 0.9269 - val_loss: 0.5748 - val_accuracy: 0.8810\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2236 - accuracy: 0.9293 - val_loss: 0.6004 - val_accuracy: 0.8738\n",
            "adam10500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 42.9312 - accuracy: 0.6930 - val_loss: 6.0958 - val_accuracy: 0.8178\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.1043 - accuracy: 0.8491 - val_loss: 2.0821 - val_accuracy: 0.8442\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.4011 - accuracy: 0.8684 - val_loss: 1.3791 - val_accuracy: 0.8537\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.9076 - accuracy: 0.8807 - val_loss: 1.0037 - val_accuracy: 0.8661\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.6726 - accuracy: 0.8884 - val_loss: 0.9334 - val_accuracy: 0.8658\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.5628 - accuracy: 0.8924 - val_loss: 0.8760 - val_accuracy: 0.8681\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.4755 - accuracy: 0.8985 - val_loss: 0.8326 - val_accuracy: 0.8679\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3935 - accuracy: 0.9079 - val_loss: 0.7958 - val_accuracy: 0.8759\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3764 - accuracy: 0.9090 - val_loss: 0.7735 - val_accuracy: 0.8652\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3177 - accuracy: 0.9162 - val_loss: 0.6826 - val_accuracy: 0.8792\n",
            "adam101000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 119.9634 - accuracy: 0.3770 - val_loss: 60.4411 - val_accuracy: 0.5978\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 31.3694 - accuracy: 0.6918 - val_loss: 18.8015 - val_accuracy: 0.7333\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 14.3736 - accuracy: 0.7692 - val_loss: 10.2170 - val_accuracy: 0.7965\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 7.1064 - accuracy: 0.8187 - val_loss: 6.3590 - val_accuracy: 0.8124\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 4.7388 - accuracy: 0.8311 - val_loss: 4.3199 - val_accuracy: 0.8261\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 3.3429 - accuracy: 0.8472 - val_loss: 3.1964 - val_accuracy: 0.8391\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.4839 - accuracy: 0.8590 - val_loss: 2.4361 - val_accuracy: 0.8463\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.9388 - accuracy: 0.8640 - val_loss: 2.0146 - val_accuracy: 0.8508\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.6060 - accuracy: 0.8687 - val_loss: 1.7299 - val_accuracy: 0.8547\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.3755 - accuracy: 0.8717 - val_loss: 1.5344 - val_accuracy: 0.8532\n",
            "adam105000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 14.8258 - accuracy: 0.7765 - val_loss: 1.6695 - val_accuracy: 0.8418\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 1.0810 - accuracy: 0.8563 - val_loss: 1.0273 - val_accuracy: 0.8496\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.6577 - accuracy: 0.8716 - val_loss: 0.7352 - val_accuracy: 0.8609\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.4466 - accuracy: 0.8875 - val_loss: 0.5940 - val_accuracy: 0.8666\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.3446 - accuracy: 0.9005 - val_loss: 0.5090 - val_accuracy: 0.8802\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2968 - accuracy: 0.9070 - val_loss: 0.5207 - val_accuracy: 0.8747\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2686 - accuracy: 0.9132 - val_loss: 0.4915 - val_accuracy: 0.8820\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.2442 - accuracy: 0.9186 - val_loss: 0.4924 - val_accuracy: 0.8731\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2261 - accuracy: 0.9227 - val_loss: 0.5117 - val_accuracy: 0.8744\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2103 - accuracy: 0.9265 - val_loss: 0.4512 - val_accuracy: 0.8812\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2021 - accuracy: 0.9288 - val_loss: 0.4546 - val_accuracy: 0.8811\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1904 - accuracy: 0.9348 - val_loss: 0.4626 - val_accuracy: 0.8835\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1911 - accuracy: 0.9342 - val_loss: 0.4766 - val_accuracy: 0.8791\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1703 - accuracy: 0.9382 - val_loss: 0.4390 - val_accuracy: 0.8858\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1622 - accuracy: 0.9433 - val_loss: 0.4435 - val_accuracy: 0.8853\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1647 - accuracy: 0.9416 - val_loss: 0.4854 - val_accuracy: 0.8821\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.1635 - accuracy: 0.9419 - val_loss: 0.4853 - val_accuracy: 0.8804\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.1556 - accuracy: 0.9444 - val_loss: 0.4777 - val_accuracy: 0.8819\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1639 - accuracy: 0.9412 - val_loss: 0.4647 - val_accuracy: 0.8848\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1598 - accuracy: 0.9420 - val_loss: 0.4982 - val_accuracy: 0.8769\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1574 - accuracy: 0.9445 - val_loss: 0.6251 - val_accuracy: 0.8691\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1479 - accuracy: 0.9488 - val_loss: 0.4831 - val_accuracy: 0.8837\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1410 - accuracy: 0.9500 - val_loss: 0.4639 - val_accuracy: 0.8891\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1367 - accuracy: 0.9518 - val_loss: 0.4894 - val_accuracy: 0.8895\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1328 - accuracy: 0.9523 - val_loss: 0.4792 - val_accuracy: 0.8913\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1317 - accuracy: 0.9526 - val_loss: 0.4975 - val_accuracy: 0.8862\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1385 - accuracy: 0.9508 - val_loss: 0.5041 - val_accuracy: 0.8836\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1229 - accuracy: 0.9558 - val_loss: 0.5247 - val_accuracy: 0.8831\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1334 - accuracy: 0.9520 - val_loss: 0.5198 - val_accuracy: 0.8854\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1301 - accuracy: 0.9532 - val_loss: 0.5222 - val_accuracy: 0.8849\n",
            "adam30500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 25.5999 - accuracy: 0.7186 - val_loss: 3.4629 - val_accuracy: 0.8364\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.0670 - accuracy: 0.8522 - val_loss: 1.5603 - val_accuracy: 0.8517\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.0879 - accuracy: 0.8683 - val_loss: 1.2290 - val_accuracy: 0.8410\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.7631 - accuracy: 0.8787 - val_loss: 1.0410 - val_accuracy: 0.8503\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.6017 - accuracy: 0.8859 - val_loss: 1.1023 - val_accuracy: 0.8293\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.5100 - accuracy: 0.8928 - val_loss: 0.7796 - val_accuracy: 0.8652\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4215 - accuracy: 0.8996 - val_loss: 0.7258 - val_accuracy: 0.8724\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3663 - accuracy: 0.9065 - val_loss: 0.6988 - val_accuracy: 0.8734\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3257 - accuracy: 0.9116 - val_loss: 0.7109 - val_accuracy: 0.8736\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3045 - accuracy: 0.9140 - val_loss: 0.6620 - val_accuracy: 0.8768\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2703 - accuracy: 0.9194 - val_loss: 0.6720 - val_accuracy: 0.8704\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2714 - accuracy: 0.9207 - val_loss: 0.6480 - val_accuracy: 0.8766\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2440 - accuracy: 0.9270 - val_loss: 0.7036 - val_accuracy: 0.8685\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2201 - accuracy: 0.9305 - val_loss: 0.6358 - val_accuracy: 0.8808\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1991 - accuracy: 0.9347 - val_loss: 0.5990 - val_accuracy: 0.8837\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1881 - accuracy: 0.9376 - val_loss: 0.6255 - val_accuracy: 0.8788\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2096 - accuracy: 0.9336 - val_loss: 0.6216 - val_accuracy: 0.8827\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1995 - accuracy: 0.9361 - val_loss: 0.6576 - val_accuracy: 0.8785\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1622 - accuracy: 0.9439 - val_loss: 0.6435 - val_accuracy: 0.8784\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1760 - accuracy: 0.9411 - val_loss: 0.6388 - val_accuracy: 0.8819\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1932 - accuracy: 0.9396 - val_loss: 0.7177 - val_accuracy: 0.8774\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1623 - accuracy: 0.9454 - val_loss: 0.5886 - val_accuracy: 0.8856\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1535 - accuracy: 0.9490 - val_loss: 0.6231 - val_accuracy: 0.8785\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1419 - accuracy: 0.9518 - val_loss: 0.6078 - val_accuracy: 0.8863\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1424 - accuracy: 0.9506 - val_loss: 0.6211 - val_accuracy: 0.8821\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1550 - accuracy: 0.9476 - val_loss: 0.6464 - val_accuracy: 0.8825\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1540 - accuracy: 0.9474 - val_loss: 0.6069 - val_accuracy: 0.8853\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1321 - accuracy: 0.9543 - val_loss: 0.6573 - val_accuracy: 0.8810\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1611 - accuracy: 0.9477 - val_loss: 0.6179 - val_accuracy: 0.8896\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1308 - accuracy: 0.9552 - val_loss: 0.6361 - val_accuracy: 0.8825\n",
            "adam301000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 147.7179 - accuracy: 0.4348 - val_loss: 27.2422 - val_accuracy: 0.6710\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 32.6031 - accuracy: 0.6740 - val_loss: 23.1153 - val_accuracy: 0.6734\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 13.3785 - accuracy: 0.7637 - val_loss: 10.3997 - val_accuracy: 0.7583\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 7.0920 - accuracy: 0.8050 - val_loss: 6.0133 - val_accuracy: 0.8124\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 4.4001 - accuracy: 0.8377 - val_loss: 3.9477 - val_accuracy: 0.8351\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 3.0585 - accuracy: 0.8519 - val_loss: 2.8835 - val_accuracy: 0.8434\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2669 - accuracy: 0.8582 - val_loss: 2.2848 - val_accuracy: 0.8467\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.7744 - accuracy: 0.8641 - val_loss: 1.8557 - val_accuracy: 0.8479\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.4432 - accuracy: 0.8666 - val_loss: 1.5877 - val_accuracy: 0.8494\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.2214 - accuracy: 0.8721 - val_loss: 1.4067 - val_accuracy: 0.8568\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 1.0633 - accuracy: 0.8756 - val_loss: 1.2825 - val_accuracy: 0.8609\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.9393 - accuracy: 0.8805 - val_loss: 1.1902 - val_accuracy: 0.8610\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.8410 - accuracy: 0.8832 - val_loss: 1.1293 - val_accuracy: 0.8595\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.7686 - accuracy: 0.8863 - val_loss: 1.0659 - val_accuracy: 0.8643\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.6994 - accuracy: 0.8886 - val_loss: 1.0107 - val_accuracy: 0.8647\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.6423 - accuracy: 0.8921 - val_loss: 0.9722 - val_accuracy: 0.8641\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5992 - accuracy: 0.8946 - val_loss: 0.9517 - val_accuracy: 0.8623\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5511 - accuracy: 0.8975 - val_loss: 0.9055 - val_accuracy: 0.8655\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5142 - accuracy: 0.9005 - val_loss: 0.8871 - val_accuracy: 0.8665\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.4845 - accuracy: 0.9015 - val_loss: 0.8732 - val_accuracy: 0.8681\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4643 - accuracy: 0.9032 - val_loss: 0.8730 - val_accuracy: 0.8669\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4457 - accuracy: 0.9044 - val_loss: 0.8430 - val_accuracy: 0.8685\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4160 - accuracy: 0.9074 - val_loss: 0.8308 - val_accuracy: 0.8665\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3946 - accuracy: 0.9085 - val_loss: 0.8028 - val_accuracy: 0.8700\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3675 - accuracy: 0.9118 - val_loss: 0.7956 - val_accuracy: 0.8718\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3519 - accuracy: 0.9139 - val_loss: 0.7818 - val_accuracy: 0.8695\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3394 - accuracy: 0.9153 - val_loss: 0.7969 - val_accuracy: 0.8649\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3354 - accuracy: 0.9144 - val_loss: 0.7770 - val_accuracy: 0.8724\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3245 - accuracy: 0.9168 - val_loss: 0.7720 - val_accuracy: 0.8718\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3069 - accuracy: 0.9181 - val_loss: 0.7746 - val_accuracy: 0.8675\n",
            "adam305000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 22.3035 - accuracy: 0.7715 - val_loss: 2.1917 - val_accuracy: 0.8218\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2828 - accuracy: 0.8602 - val_loss: 1.2159 - val_accuracy: 0.8499\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.7621 - accuracy: 0.8761 - val_loss: 0.8263 - val_accuracy: 0.8642\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.5386 - accuracy: 0.8864 - val_loss: 0.7237 - val_accuracy: 0.8614\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.4311 - accuracy: 0.8960 - val_loss: 0.7097 - val_accuracy: 0.8523\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.3612 - accuracy: 0.9037 - val_loss: 0.5881 - val_accuracy: 0.8785\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.3118 - accuracy: 0.9125 - val_loss: 0.5714 - val_accuracy: 0.8805\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2938 - accuracy: 0.9157 - val_loss: 0.5404 - val_accuracy: 0.8821\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2598 - accuracy: 0.9215 - val_loss: 0.5968 - val_accuracy: 0.8756\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2491 - accuracy: 0.9234 - val_loss: 0.5731 - val_accuracy: 0.8785\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2256 - accuracy: 0.9271 - val_loss: 0.5046 - val_accuracy: 0.8862\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2111 - accuracy: 0.9304 - val_loss: 0.5414 - val_accuracy: 0.8815\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2164 - accuracy: 0.9292 - val_loss: 0.5642 - val_accuracy: 0.8691\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1951 - accuracy: 0.9358 - val_loss: 0.5024 - val_accuracy: 0.8856\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1888 - accuracy: 0.9363 - val_loss: 0.5007 - val_accuracy: 0.8850\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1755 - accuracy: 0.9405 - val_loss: 0.5379 - val_accuracy: 0.8748\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1749 - accuracy: 0.9398 - val_loss: 0.4915 - val_accuracy: 0.8893\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1652 - accuracy: 0.9442 - val_loss: 0.5254 - val_accuracy: 0.8870\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1623 - accuracy: 0.9438 - val_loss: 0.5078 - val_accuracy: 0.8824\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1608 - accuracy: 0.9448 - val_loss: 0.6147 - val_accuracy: 0.8650\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1553 - accuracy: 0.9455 - val_loss: 0.4937 - val_accuracy: 0.8879\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1370 - accuracy: 0.9509 - val_loss: 0.5050 - val_accuracy: 0.8868\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1480 - accuracy: 0.9476 - val_loss: 0.5274 - val_accuracy: 0.8863\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1421 - accuracy: 0.9490 - val_loss: 0.4886 - val_accuracy: 0.8913\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1392 - accuracy: 0.9506 - val_loss: 0.5096 - val_accuracy: 0.8884\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1345 - accuracy: 0.9511 - val_loss: 0.5065 - val_accuracy: 0.8892\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1506 - accuracy: 0.9482 - val_loss: 0.5457 - val_accuracy: 0.8802\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1338 - accuracy: 0.9516 - val_loss: 0.5127 - val_accuracy: 0.8883\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1251 - accuracy: 0.9553 - val_loss: 0.5229 - val_accuracy: 0.8867\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1267 - accuracy: 0.9550 - val_loss: 0.5407 - val_accuracy: 0.8880\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1262 - accuracy: 0.9537 - val_loss: 0.5347 - val_accuracy: 0.8838\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1170 - accuracy: 0.9575 - val_loss: 0.5288 - val_accuracy: 0.8856\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1286 - accuracy: 0.9538 - val_loss: 0.5232 - val_accuracy: 0.8883\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1152 - accuracy: 0.9579 - val_loss: 0.5524 - val_accuracy: 0.8842\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1142 - accuracy: 0.9586 - val_loss: 0.5610 - val_accuracy: 0.8860\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1175 - accuracy: 0.9575 - val_loss: 0.5689 - val_accuracy: 0.8863\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1174 - accuracy: 0.9565 - val_loss: 0.5685 - val_accuracy: 0.8867\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1094 - accuracy: 0.9604 - val_loss: 0.5646 - val_accuracy: 0.8877\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1155 - accuracy: 0.9584 - val_loss: 0.5967 - val_accuracy: 0.8877\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1206 - accuracy: 0.9566 - val_loss: 0.5775 - val_accuracy: 0.8900\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1114 - accuracy: 0.9596 - val_loss: 0.6320 - val_accuracy: 0.8844\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1130 - accuracy: 0.9581 - val_loss: 0.5718 - val_accuracy: 0.8871\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1046 - accuracy: 0.9620 - val_loss: 0.6039 - val_accuracy: 0.8864\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1118 - accuracy: 0.9600 - val_loss: 0.5887 - val_accuracy: 0.8919\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1064 - accuracy: 0.9607 - val_loss: 0.6153 - val_accuracy: 0.8839\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1152 - accuracy: 0.9574 - val_loss: 0.5802 - val_accuracy: 0.8918\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1017 - accuracy: 0.9621 - val_loss: 0.5977 - val_accuracy: 0.8885\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0956 - accuracy: 0.9647 - val_loss: 0.6225 - val_accuracy: 0.8861\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1043 - accuracy: 0.9616 - val_loss: 0.6481 - val_accuracy: 0.8776\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1000 - accuracy: 0.9629 - val_loss: 0.6352 - val_accuracy: 0.8847\n",
            "adam50500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 45.0243 - accuracy: 0.6918 - val_loss: 6.1358 - val_accuracy: 0.8229\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 3.1832 - accuracy: 0.8446 - val_loss: 2.0864 - val_accuracy: 0.8369\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.4628 - accuracy: 0.8604 - val_loss: 1.4390 - val_accuracy: 0.8484\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.9880 - accuracy: 0.8723 - val_loss: 1.1165 - val_accuracy: 0.8673\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.7413 - accuracy: 0.8837 - val_loss: 0.9705 - val_accuracy: 0.8638\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.6206 - accuracy: 0.8872 - val_loss: 0.9033 - val_accuracy: 0.8646\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.5142 - accuracy: 0.8946 - val_loss: 0.8417 - val_accuracy: 0.8672\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4385 - accuracy: 0.9021 - val_loss: 0.8564 - val_accuracy: 0.8660\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4194 - accuracy: 0.9025 - val_loss: 0.7640 - val_accuracy: 0.8734\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.3571 - accuracy: 0.9097 - val_loss: 0.8001 - val_accuracy: 0.8638\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3319 - accuracy: 0.9121 - val_loss: 0.7342 - val_accuracy: 0.8751\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2864 - accuracy: 0.9188 - val_loss: 0.6652 - val_accuracy: 0.8807\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2889 - accuracy: 0.9189 - val_loss: 0.6724 - val_accuracy: 0.8762\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2552 - accuracy: 0.9234 - val_loss: 0.8765 - val_accuracy: 0.8494\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2575 - accuracy: 0.9242 - val_loss: 0.6693 - val_accuracy: 0.8766\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2225 - accuracy: 0.9309 - val_loss: 0.6354 - val_accuracy: 0.8815\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2162 - accuracy: 0.9316 - val_loss: 0.6284 - val_accuracy: 0.8872\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2160 - accuracy: 0.9321 - val_loss: 0.6458 - val_accuracy: 0.8780\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1917 - accuracy: 0.9372 - val_loss: 0.6384 - val_accuracy: 0.8845\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1897 - accuracy: 0.9389 - val_loss: 0.6182 - val_accuracy: 0.8869\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1871 - accuracy: 0.9392 - val_loss: 0.6119 - val_accuracy: 0.8839\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1622 - accuracy: 0.9452 - val_loss: 0.6366 - val_accuracy: 0.8834\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1798 - accuracy: 0.9396 - val_loss: 0.6673 - val_accuracy: 0.8709\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1584 - accuracy: 0.9456 - val_loss: 0.6478 - val_accuracy: 0.8760\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1457 - accuracy: 0.9503 - val_loss: 0.6433 - val_accuracy: 0.8807\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1736 - accuracy: 0.9418 - val_loss: 0.6451 - val_accuracy: 0.8792\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1603 - accuracy: 0.9453 - val_loss: 0.6183 - val_accuracy: 0.8890\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1539 - accuracy: 0.9482 - val_loss: 0.6450 - val_accuracy: 0.8825\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1561 - accuracy: 0.9471 - val_loss: 0.6510 - val_accuracy: 0.8878\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1546 - accuracy: 0.9491 - val_loss: 0.6972 - val_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1465 - accuracy: 0.9509 - val_loss: 0.6344 - val_accuracy: 0.8880\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1255 - accuracy: 0.9560 - val_loss: 0.6362 - val_accuracy: 0.8826\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1272 - accuracy: 0.9552 - val_loss: 0.6360 - val_accuracy: 0.8871\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1248 - accuracy: 0.9556 - val_loss: 0.6707 - val_accuracy: 0.8846\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1467 - accuracy: 0.9506 - val_loss: 0.7572 - val_accuracy: 0.8733\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1509 - accuracy: 0.9498 - val_loss: 0.6575 - val_accuracy: 0.8847\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1262 - accuracy: 0.9570 - val_loss: 0.6762 - val_accuracy: 0.8825\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1419 - accuracy: 0.9526 - val_loss: 0.7053 - val_accuracy: 0.8754\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1395 - accuracy: 0.9531 - val_loss: 0.6676 - val_accuracy: 0.8844\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1323 - accuracy: 0.9549 - val_loss: 0.6566 - val_accuracy: 0.8894\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1157 - accuracy: 0.9607 - val_loss: 0.7388 - val_accuracy: 0.8690\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1383 - accuracy: 0.9540 - val_loss: 0.6670 - val_accuracy: 0.8879\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1344 - accuracy: 0.9543 - val_loss: 0.6925 - val_accuracy: 0.8839\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1170 - accuracy: 0.9600 - val_loss: 0.6726 - val_accuracy: 0.8883\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1058 - accuracy: 0.9627 - val_loss: 0.6681 - val_accuracy: 0.8831\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1004 - accuracy: 0.9645 - val_loss: 0.6891 - val_accuracy: 0.8813\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1050 - accuracy: 0.9628 - val_loss: 0.6871 - val_accuracy: 0.8801\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0990 - accuracy: 0.9647 - val_loss: 0.6846 - val_accuracy: 0.8881\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1130 - accuracy: 0.9610 - val_loss: 0.6784 - val_accuracy: 0.8878\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1088 - accuracy: 0.9626 - val_loss: 0.7287 - val_accuracy: 0.8822\n",
            "adam501000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 132.3211 - accuracy: 0.4197 - val_loss: 49.9529 - val_accuracy: 0.5183\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 32.6407 - accuracy: 0.6683 - val_loss: 19.5180 - val_accuracy: 0.7706\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 14.3620 - accuracy: 0.7845 - val_loss: 10.8867 - val_accuracy: 0.8019\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 8.5559 - accuracy: 0.8216 - val_loss: 7.5674 - val_accuracy: 0.8142\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 5.6797 - accuracy: 0.8378 - val_loss: 5.2177 - val_accuracy: 0.8324\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 3.9848 - accuracy: 0.8510 - val_loss: 3.8729 - val_accuracy: 0.8473\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.9628 - accuracy: 0.8613 - val_loss: 3.0401 - val_accuracy: 0.8504\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2546 - accuracy: 0.8661 - val_loss: 2.4345 - val_accuracy: 0.8532\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.7996 - accuracy: 0.8684 - val_loss: 2.0303 - val_accuracy: 0.8526\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.5141 - accuracy: 0.8724 - val_loss: 1.7962 - val_accuracy: 0.8571\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.2935 - accuracy: 0.8762 - val_loss: 1.6671 - val_accuracy: 0.8576\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.1546 - accuracy: 0.8780 - val_loss: 1.5224 - val_accuracy: 0.8585\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.0389 - accuracy: 0.8806 - val_loss: 1.4179 - val_accuracy: 0.8622\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.9520 - accuracy: 0.8827 - val_loss: 1.3438 - val_accuracy: 0.8617\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.8640 - accuracy: 0.8863 - val_loss: 1.2962 - val_accuracy: 0.8665\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.8010 - accuracy: 0.8885 - val_loss: 1.2494 - val_accuracy: 0.8591\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.7713 - accuracy: 0.8888 - val_loss: 1.2026 - val_accuracy: 0.8624\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.0097 - accuracy: 0.8685 - val_loss: 1.2594 - val_accuracy: 0.8617\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.8162 - accuracy: 0.8878 - val_loss: 1.3458 - val_accuracy: 0.8403\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.7170 - accuracy: 0.8923 - val_loss: 1.1933 - val_accuracy: 0.8641\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.6363 - accuracy: 0.8967 - val_loss: 1.0640 - val_accuracy: 0.8662\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5812 - accuracy: 0.8999 - val_loss: 1.0402 - val_accuracy: 0.8672\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5304 - accuracy: 0.9044 - val_loss: 1.0196 - val_accuracy: 0.8703\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5256 - accuracy: 0.9022 - val_loss: 1.0136 - val_accuracy: 0.8646\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.6784 - accuracy: 0.8880 - val_loss: 1.9801 - val_accuracy: 0.8341\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.4961 - accuracy: 0.8445 - val_loss: 1.4949 - val_accuracy: 0.8589\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.0097 - accuracy: 0.8808 - val_loss: 1.2781 - val_accuracy: 0.8657\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.6046 - accuracy: 0.9063 - val_loss: 1.0599 - val_accuracy: 0.8726\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4695 - accuracy: 0.9131 - val_loss: 0.9808 - val_accuracy: 0.8737\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4062 - accuracy: 0.9181 - val_loss: 0.9205 - val_accuracy: 0.8735\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3755 - accuracy: 0.9200 - val_loss: 0.9011 - val_accuracy: 0.8739\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3580 - accuracy: 0.9210 - val_loss: 0.9329 - val_accuracy: 0.8640\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3568 - accuracy: 0.9195 - val_loss: 0.8884 - val_accuracy: 0.8730\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3197 - accuracy: 0.9251 - val_loss: 0.8680 - val_accuracy: 0.8724\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3092 - accuracy: 0.9262 - val_loss: 0.8720 - val_accuracy: 0.8741\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3090 - accuracy: 0.9241 - val_loss: 0.8873 - val_accuracy: 0.8707\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3087 - accuracy: 0.9240 - val_loss: 0.8581 - val_accuracy: 0.8733\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2979 - accuracy: 0.9252 - val_loss: 0.8848 - val_accuracy: 0.8717\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3497 - accuracy: 0.9153 - val_loss: 1.2554 - val_accuracy: 0.8358\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4875 - accuracy: 0.9009 - val_loss: 0.9491 - val_accuracy: 0.8715\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3502 - accuracy: 0.9211 - val_loss: 0.9227 - val_accuracy: 0.8655\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3259 - accuracy: 0.9219 - val_loss: 0.8936 - val_accuracy: 0.8735\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2878 - accuracy: 0.9271 - val_loss: 0.8491 - val_accuracy: 0.8709\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2650 - accuracy: 0.9309 - val_loss: 0.8125 - val_accuracy: 0.8760\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2337 - accuracy: 0.9384 - val_loss: 0.7964 - val_accuracy: 0.8759\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2311 - accuracy: 0.9369 - val_loss: 0.8211 - val_accuracy: 0.8774\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2316 - accuracy: 0.9354 - val_loss: 0.7935 - val_accuracy: 0.8771\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2160 - accuracy: 0.9400 - val_loss: 0.8031 - val_accuracy: 0.8741\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2115 - accuracy: 0.9397 - val_loss: 0.7777 - val_accuracy: 0.8761\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2190 - accuracy: 0.9374 - val_loss: 0.8039 - val_accuracy: 0.8764\n",
            "adam505000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 30.7873 - accuracy: 0.7469 - val_loss: 1.4932 - val_accuracy: 0.7986\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.6248 - accuracy: 0.8466 - val_loss: 0.4332 - val_accuracy: 0.8553\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3475 - accuracy: 0.8784 - val_loss: 0.3851 - val_accuracy: 0.8724\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2909 - accuracy: 0.8958 - val_loss: 0.3913 - val_accuracy: 0.8680\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2599 - accuracy: 0.9049 - val_loss: 0.4195 - val_accuracy: 0.8657\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2386 - accuracy: 0.9133 - val_loss: 0.3761 - val_accuracy: 0.8803\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2234 - accuracy: 0.9179 - val_loss: 0.4160 - val_accuracy: 0.8684\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2120 - accuracy: 0.9215 - val_loss: 0.4415 - val_accuracy: 0.8684\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2018 - accuracy: 0.9262 - val_loss: 0.4168 - val_accuracy: 0.8764\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1946 - accuracy: 0.9271 - val_loss: 0.4326 - val_accuracy: 0.8779\n",
            "rmsprop10500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 68.4364 - accuracy: 0.6746 - val_loss: 10.4799 - val_accuracy: 0.7900\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.4406 - accuracy: 0.8076 - val_loss: 2.3999 - val_accuracy: 0.8212\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.9625 - accuracy: 0.8430 - val_loss: 0.5360 - val_accuracy: 0.8480\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4150 - accuracy: 0.8643 - val_loss: 0.4117 - val_accuracy: 0.8651\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.3303 - accuracy: 0.8828 - val_loss: 0.3815 - val_accuracy: 0.8752\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2898 - accuracy: 0.8944 - val_loss: 0.3893 - val_accuracy: 0.8770\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2607 - accuracy: 0.9042 - val_loss: 0.3789 - val_accuracy: 0.8763\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2410 - accuracy: 0.9110 - val_loss: 0.3904 - val_accuracy: 0.8777\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2274 - accuracy: 0.9158 - val_loss: 0.4234 - val_accuracy: 0.8729\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2132 - accuracy: 0.9204 - val_loss: 0.4167 - val_accuracy: 0.8760\n",
            "rmsprop101000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 352.1982 - accuracy: 0.3536 - val_loss: 61.9721 - val_accuracy: 0.6284\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 46.3212 - accuracy: 0.6753 - val_loss: 25.2734 - val_accuracy: 0.7164\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 31.3680 - accuracy: 0.6993 - val_loss: 21.5677 - val_accuracy: 0.7220\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 25.3584 - accuracy: 0.7435 - val_loss: 10.3859 - val_accuracy: 0.7582\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 13.9820 - accuracy: 0.7746 - val_loss: 8.1844 - val_accuracy: 0.7929\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 8.7639 - accuracy: 0.7942 - val_loss: 10.4570 - val_accuracy: 0.7232\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 6.4287 - accuracy: 0.8077 - val_loss: 3.7559 - val_accuracy: 0.8324\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 4.0607 - accuracy: 0.8162 - val_loss: 2.5312 - val_accuracy: 0.8422\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.6182 - accuracy: 0.8408 - val_loss: 3.3199 - val_accuracy: 0.7934\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.8789 - accuracy: 0.8379 - val_loss: 1.1551 - val_accuracy: 0.8561\n",
            "rmsprop105000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 26.8858 - accuracy: 0.7454 - val_loss: 0.8682 - val_accuracy: 0.8456\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.5617 - accuracy: 0.8467 - val_loss: 0.4627 - val_accuracy: 0.8456\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3390 - accuracy: 0.8805 - val_loss: 0.4265 - val_accuracy: 0.8552\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2846 - accuracy: 0.8979 - val_loss: 0.3856 - val_accuracy: 0.8736\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2552 - accuracy: 0.9081 - val_loss: 0.4044 - val_accuracy: 0.8736\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2366 - accuracy: 0.9134 - val_loss: 0.3944 - val_accuracy: 0.8810\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2193 - accuracy: 0.9192 - val_loss: 0.3909 - val_accuracy: 0.8839\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2091 - accuracy: 0.9230 - val_loss: 0.4191 - val_accuracy: 0.8826\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2004 - accuracy: 0.9254 - val_loss: 0.4078 - val_accuracy: 0.8854\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1914 - accuracy: 0.9283 - val_loss: 0.4244 - val_accuracy: 0.8792\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1845 - accuracy: 0.9309 - val_loss: 0.4338 - val_accuracy: 0.8826\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1794 - accuracy: 0.9333 - val_loss: 0.4416 - val_accuracy: 0.8819\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1729 - accuracy: 0.9351 - val_loss: 0.4702 - val_accuracy: 0.8759\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1695 - accuracy: 0.9362 - val_loss: 0.4777 - val_accuracy: 0.8824\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1636 - accuracy: 0.9395 - val_loss: 0.4913 - val_accuracy: 0.8826\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1591 - accuracy: 0.9406 - val_loss: 0.5281 - val_accuracy: 0.8782\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1571 - accuracy: 0.9417 - val_loss: 0.5174 - val_accuracy: 0.8755\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1532 - accuracy: 0.9418 - val_loss: 0.5002 - val_accuracy: 0.8815\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1487 - accuracy: 0.9440 - val_loss: 0.5597 - val_accuracy: 0.8694\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1456 - accuracy: 0.9447 - val_loss: 0.5466 - val_accuracy: 0.8774\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1424 - accuracy: 0.9468 - val_loss: 0.5627 - val_accuracy: 0.8806\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1426 - accuracy: 0.9478 - val_loss: 0.5720 - val_accuracy: 0.8792\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1386 - accuracy: 0.9479 - val_loss: 0.5810 - val_accuracy: 0.8810\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1354 - accuracy: 0.9484 - val_loss: 0.5917 - val_accuracy: 0.8795\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1332 - accuracy: 0.9496 - val_loss: 0.6120 - val_accuracy: 0.8794\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1308 - accuracy: 0.9511 - val_loss: 0.6341 - val_accuracy: 0.8783\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1289 - accuracy: 0.9521 - val_loss: 0.6487 - val_accuracy: 0.8801\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1266 - accuracy: 0.9529 - val_loss: 0.6364 - val_accuracy: 0.8813\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1256 - accuracy: 0.9532 - val_loss: 0.6559 - val_accuracy: 0.8807\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1221 - accuracy: 0.9552 - val_loss: 0.6930 - val_accuracy: 0.8741\n",
            "rmsprop30500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 68.9480 - accuracy: 0.6697 - val_loss: 6.7524 - val_accuracy: 0.8060\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.0558 - accuracy: 0.8134 - val_loss: 1.6500 - val_accuracy: 0.8252\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.9771 - accuracy: 0.8441 - val_loss: 0.5328 - val_accuracy: 0.8583\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4194 - accuracy: 0.8633 - val_loss: 0.4276 - val_accuracy: 0.8601\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.3253 - accuracy: 0.8834 - val_loss: 0.4218 - val_accuracy: 0.8581\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2862 - accuracy: 0.8967 - val_loss: 0.3722 - val_accuracy: 0.8791\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2586 - accuracy: 0.9061 - val_loss: 0.3965 - val_accuracy: 0.8769\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2454 - accuracy: 0.9108 - val_loss: 0.3879 - val_accuracy: 0.8787\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2250 - accuracy: 0.9171 - val_loss: 0.4310 - val_accuracy: 0.8787\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2168 - accuracy: 0.9203 - val_loss: 0.4266 - val_accuracy: 0.8774\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2039 - accuracy: 0.9248 - val_loss: 0.4433 - val_accuracy: 0.8726\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1973 - accuracy: 0.9270 - val_loss: 0.4319 - val_accuracy: 0.8770\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1886 - accuracy: 0.9305 - val_loss: 0.4534 - val_accuracy: 0.8786\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1852 - accuracy: 0.9312 - val_loss: 0.4535 - val_accuracy: 0.8765\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1769 - accuracy: 0.9345 - val_loss: 0.4653 - val_accuracy: 0.8800\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1716 - accuracy: 0.9360 - val_loss: 0.4738 - val_accuracy: 0.8796\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1680 - accuracy: 0.9369 - val_loss: 0.4826 - val_accuracy: 0.8826\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1644 - accuracy: 0.9390 - val_loss: 0.5191 - val_accuracy: 0.8737\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1599 - accuracy: 0.9401 - val_loss: 0.4984 - val_accuracy: 0.8775\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1552 - accuracy: 0.9416 - val_loss: 0.5291 - val_accuracy: 0.8797\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1521 - accuracy: 0.9420 - val_loss: 0.5697 - val_accuracy: 0.8685\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1506 - accuracy: 0.9444 - val_loss: 0.5288 - val_accuracy: 0.8783\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1450 - accuracy: 0.9458 - val_loss: 0.5583 - val_accuracy: 0.8793\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1450 - accuracy: 0.9459 - val_loss: 0.6261 - val_accuracy: 0.8621\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1392 - accuracy: 0.9483 - val_loss: 0.6433 - val_accuracy: 0.8624\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1381 - accuracy: 0.9481 - val_loss: 0.5798 - val_accuracy: 0.8769\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1368 - accuracy: 0.9491 - val_loss: 0.6122 - val_accuracy: 0.8704\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1336 - accuracy: 0.9496 - val_loss: 0.6108 - val_accuracy: 0.8792\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1321 - accuracy: 0.9502 - val_loss: 0.6267 - val_accuracy: 0.8713\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1291 - accuracy: 0.9516 - val_loss: 0.6457 - val_accuracy: 0.8748\n",
            "rmsprop301000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 243.2267 - accuracy: 0.3738 - val_loss: 22.8691 - val_accuracy: 0.7444\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 25.8247 - accuracy: 0.7380 - val_loss: 34.0673 - val_accuracy: 0.7632\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 33.4386 - accuracy: 0.7072 - val_loss: 17.8351 - val_accuracy: 0.7830\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 19.8381 - accuracy: 0.7612 - val_loss: 27.2997 - val_accuracy: 0.6950\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 14.6237 - accuracy: 0.7636 - val_loss: 19.0682 - val_accuracy: 0.7895\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 9.5489 - accuracy: 0.7971 - val_loss: 7.5236 - val_accuracy: 0.7805\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 5.5388 - accuracy: 0.8107 - val_loss: 5.1920 - val_accuracy: 0.7865\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 3.8098 - accuracy: 0.8181 - val_loss: 4.4185 - val_accuracy: 0.7625\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3780 - accuracy: 0.8304 - val_loss: 3.1110 - val_accuracy: 0.7741\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.5252 - accuracy: 0.8367 - val_loss: 1.1061 - val_accuracy: 0.8475\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.9324 - accuracy: 0.8531 - val_loss: 0.8040 - val_accuracy: 0.8502\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.7653 - accuracy: 0.8490 - val_loss: 0.6472 - val_accuracy: 0.8494\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5822 - accuracy: 0.8585 - val_loss: 0.5675 - val_accuracy: 0.8534\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4976 - accuracy: 0.8596 - val_loss: 0.6547 - val_accuracy: 0.8288\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4325 - accuracy: 0.8657 - val_loss: 0.5769 - val_accuracy: 0.8491\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4096 - accuracy: 0.8693 - val_loss: 0.4991 - val_accuracy: 0.8592\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3570 - accuracy: 0.8808 - val_loss: 0.5532 - val_accuracy: 0.8429\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3466 - accuracy: 0.8801 - val_loss: 0.4632 - val_accuracy: 0.8646\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3177 - accuracy: 0.8890 - val_loss: 0.4276 - val_accuracy: 0.8620\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2961 - accuracy: 0.8941 - val_loss: 0.4687 - val_accuracy: 0.8534\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2922 - accuracy: 0.8975 - val_loss: 0.4231 - val_accuracy: 0.8632\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2470 - accuracy: 0.9095 - val_loss: 0.4655 - val_accuracy: 0.8587\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2717 - accuracy: 0.9007 - val_loss: 0.4669 - val_accuracy: 0.8564\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2439 - accuracy: 0.9103 - val_loss: 0.4616 - val_accuracy: 0.8655\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2491 - accuracy: 0.9094 - val_loss: 0.4873 - val_accuracy: 0.8571\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2372 - accuracy: 0.9141 - val_loss: 0.5071 - val_accuracy: 0.8549\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2226 - accuracy: 0.9175 - val_loss: 0.4444 - val_accuracy: 0.8760\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2195 - accuracy: 0.9200 - val_loss: 0.4829 - val_accuracy: 0.8689\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2201 - accuracy: 0.9176 - val_loss: 0.4426 - val_accuracy: 0.8727\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2081 - accuracy: 0.9231 - val_loss: 0.4747 - val_accuracy: 0.8618\n",
            "rmsprop305000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 35.7916 - accuracy: 0.7292 - val_loss: 1.8260 - val_accuracy: 0.8121\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.6736 - accuracy: 0.8470 - val_loss: 0.4409 - val_accuracy: 0.8493\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3419 - accuracy: 0.8802 - val_loss: 0.4129 - val_accuracy: 0.8630\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2846 - accuracy: 0.8967 - val_loss: 0.3714 - val_accuracy: 0.8795\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2523 - accuracy: 0.9080 - val_loss: 0.3832 - val_accuracy: 0.8796\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2310 - accuracy: 0.9153 - val_loss: 0.3956 - val_accuracy: 0.8812\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2160 - accuracy: 0.9202 - val_loss: 0.4561 - val_accuracy: 0.8630\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2056 - accuracy: 0.9238 - val_loss: 0.4106 - val_accuracy: 0.8812\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1956 - accuracy: 0.9277 - val_loss: 0.4331 - val_accuracy: 0.8793\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1870 - accuracy: 0.9308 - val_loss: 0.4514 - val_accuracy: 0.8763\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1818 - accuracy: 0.9327 - val_loss: 0.4331 - val_accuracy: 0.8797\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1752 - accuracy: 0.9351 - val_loss: 0.4449 - val_accuracy: 0.8827\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1687 - accuracy: 0.9382 - val_loss: 0.4850 - val_accuracy: 0.8798\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1657 - accuracy: 0.9399 - val_loss: 0.4668 - val_accuracy: 0.8818\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1599 - accuracy: 0.9408 - val_loss: 0.4789 - val_accuracy: 0.8836\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1573 - accuracy: 0.9417 - val_loss: 0.5111 - val_accuracy: 0.8747\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1524 - accuracy: 0.9427 - val_loss: 0.5083 - val_accuracy: 0.8821\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1495 - accuracy: 0.9445 - val_loss: 0.5424 - val_accuracy: 0.8787\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1485 - accuracy: 0.9445 - val_loss: 0.5315 - val_accuracy: 0.8780\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1446 - accuracy: 0.9461 - val_loss: 0.5570 - val_accuracy: 0.8780\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.1414 - accuracy: 0.9484 - val_loss: 0.5690 - val_accuracy: 0.8767\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1395 - accuracy: 0.9483 - val_loss: 0.5848 - val_accuracy: 0.8805\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.1364 - accuracy: 0.9497 - val_loss: 0.5815 - val_accuracy: 0.8803\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1344 - accuracy: 0.9504 - val_loss: 0.6182 - val_accuracy: 0.8719\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1320 - accuracy: 0.9502 - val_loss: 0.6473 - val_accuracy: 0.8742\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1301 - accuracy: 0.9520 - val_loss: 0.6359 - val_accuracy: 0.8754\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1286 - accuracy: 0.9525 - val_loss: 0.6498 - val_accuracy: 0.8785\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1269 - accuracy: 0.9535 - val_loss: 0.6737 - val_accuracy: 0.8730\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1235 - accuracy: 0.9549 - val_loss: 0.6653 - val_accuracy: 0.8778\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1231 - accuracy: 0.9547 - val_loss: 0.7020 - val_accuracy: 0.8713\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1218 - accuracy: 0.9541 - val_loss: 0.6947 - val_accuracy: 0.8738\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1189 - accuracy: 0.9552 - val_loss: 0.6825 - val_accuracy: 0.8810\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1175 - accuracy: 0.9561 - val_loss: 0.7346 - val_accuracy: 0.8775\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1160 - accuracy: 0.9573 - val_loss: 0.7405 - val_accuracy: 0.8690\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1151 - accuracy: 0.9572 - val_loss: 0.7815 - val_accuracy: 0.8735\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1139 - accuracy: 0.9582 - val_loss: 0.7544 - val_accuracy: 0.8752\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1141 - accuracy: 0.9582 - val_loss: 0.7774 - val_accuracy: 0.8727\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1134 - accuracy: 0.9578 - val_loss: 0.7626 - val_accuracy: 0.8765\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1102 - accuracy: 0.9589 - val_loss: 0.7872 - val_accuracy: 0.8780\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1101 - accuracy: 0.9586 - val_loss: 0.8523 - val_accuracy: 0.8589\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1074 - accuracy: 0.9596 - val_loss: 0.8022 - val_accuracy: 0.8739\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1074 - accuracy: 0.9604 - val_loss: 0.8048 - val_accuracy: 0.8767\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1072 - accuracy: 0.9608 - val_loss: 0.8283 - val_accuracy: 0.8681\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1055 - accuracy: 0.9609 - val_loss: 0.8715 - val_accuracy: 0.8692\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1046 - accuracy: 0.9611 - val_loss: 0.8812 - val_accuracy: 0.8732\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1033 - accuracy: 0.9613 - val_loss: 0.8994 - val_accuracy: 0.8729\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1023 - accuracy: 0.9628 - val_loss: 0.9206 - val_accuracy: 0.8702\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1002 - accuracy: 0.9630 - val_loss: 0.9018 - val_accuracy: 0.8701\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0998 - accuracy: 0.9622 - val_loss: 0.9342 - val_accuracy: 0.8717\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1003 - accuracy: 0.9624 - val_loss: 0.9304 - val_accuracy: 0.8732\n",
            "rmsprop50500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 62.7090 - accuracy: 0.6739 - val_loss: 9.9937 - val_accuracy: 0.7418\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.3622 - accuracy: 0.8128 - val_loss: 2.8443 - val_accuracy: 0.7677\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.0525 - accuracy: 0.8452 - val_loss: 0.7072 - val_accuracy: 0.8365\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4084 - accuracy: 0.8678 - val_loss: 0.4880 - val_accuracy: 0.8468\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3216 - accuracy: 0.8864 - val_loss: 0.4091 - val_accuracy: 0.8631\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2789 - accuracy: 0.8992 - val_loss: 0.3880 - val_accuracy: 0.8795\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2511 - accuracy: 0.9084 - val_loss: 0.3730 - val_accuracy: 0.8843\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2319 - accuracy: 0.9151 - val_loss: 0.3895 - val_accuracy: 0.8827\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2178 - accuracy: 0.9194 - val_loss: 0.3964 - val_accuracy: 0.8838\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2068 - accuracy: 0.9225 - val_loss: 0.4272 - val_accuracy: 0.8846\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1935 - accuracy: 0.9280 - val_loss: 0.4190 - val_accuracy: 0.8851\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1888 - accuracy: 0.9297 - val_loss: 0.4539 - val_accuracy: 0.8769\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1785 - accuracy: 0.9331 - val_loss: 0.4523 - val_accuracy: 0.8747\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1765 - accuracy: 0.9343 - val_loss: 0.4492 - val_accuracy: 0.8818\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1681 - accuracy: 0.9367 - val_loss: 0.4839 - val_accuracy: 0.8802\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1643 - accuracy: 0.9382 - val_loss: 0.4890 - val_accuracy: 0.8791\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1625 - accuracy: 0.9396 - val_loss: 0.4910 - val_accuracy: 0.8786\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1555 - accuracy: 0.9415 - val_loss: 0.4897 - val_accuracy: 0.8787\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1523 - accuracy: 0.9432 - val_loss: 0.5402 - val_accuracy: 0.8729\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1493 - accuracy: 0.9441 - val_loss: 0.5245 - val_accuracy: 0.8742\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1444 - accuracy: 0.9460 - val_loss: 0.5513 - val_accuracy: 0.8763\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1431 - accuracy: 0.9463 - val_loss: 0.5330 - val_accuracy: 0.8817\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1379 - accuracy: 0.9485 - val_loss: 0.5562 - val_accuracy: 0.8793\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1370 - accuracy: 0.9482 - val_loss: 0.5701 - val_accuracy: 0.8819\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1342 - accuracy: 0.9481 - val_loss: 0.5823 - val_accuracy: 0.8765\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1344 - accuracy: 0.9504 - val_loss: 0.5771 - val_accuracy: 0.8796\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1281 - accuracy: 0.9518 - val_loss: 0.6539 - val_accuracy: 0.8721\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1265 - accuracy: 0.9519 - val_loss: 0.6345 - val_accuracy: 0.8801\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1248 - accuracy: 0.9544 - val_loss: 0.6437 - val_accuracy: 0.8757\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1222 - accuracy: 0.9546 - val_loss: 0.7240 - val_accuracy: 0.8604\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1226 - accuracy: 0.9539 - val_loss: 0.6528 - val_accuracy: 0.8749\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1198 - accuracy: 0.9550 - val_loss: 0.6786 - val_accuracy: 0.8751\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1188 - accuracy: 0.9548 - val_loss: 0.6814 - val_accuracy: 0.8712\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1174 - accuracy: 0.9557 - val_loss: 0.6802 - val_accuracy: 0.8793\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1125 - accuracy: 0.9576 - val_loss: 0.6937 - val_accuracy: 0.8779\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1148 - accuracy: 0.9566 - val_loss: 0.7739 - val_accuracy: 0.8674\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1095 - accuracy: 0.9591 - val_loss: 0.7356 - val_accuracy: 0.8705\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1125 - accuracy: 0.9579 - val_loss: 0.7375 - val_accuracy: 0.8763\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1092 - accuracy: 0.9595 - val_loss: 0.7494 - val_accuracy: 0.8746\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1079 - accuracy: 0.9596 - val_loss: 0.7335 - val_accuracy: 0.8771\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1054 - accuracy: 0.9606 - val_loss: 0.7580 - val_accuracy: 0.8760\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1060 - accuracy: 0.9595 - val_loss: 0.7657 - val_accuracy: 0.8740\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1046 - accuracy: 0.9609 - val_loss: 0.8143 - val_accuracy: 0.8764\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1037 - accuracy: 0.9614 - val_loss: 0.8060 - val_accuracy: 0.8762\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1027 - accuracy: 0.9615 - val_loss: 0.8204 - val_accuracy: 0.8732\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1011 - accuracy: 0.9626 - val_loss: 0.8809 - val_accuracy: 0.8725\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1014 - accuracy: 0.9625 - val_loss: 0.8806 - val_accuracy: 0.8664\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0996 - accuracy: 0.9631 - val_loss: 0.8474 - val_accuracy: 0.8735\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0986 - accuracy: 0.9635 - val_loss: 0.8853 - val_accuracy: 0.8723\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0976 - accuracy: 0.9639 - val_loss: 0.8979 - val_accuracy: 0.8742\n",
            "rmsprop501000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 209.7292 - accuracy: 0.4816 - val_loss: 75.4345 - val_accuracy: 0.6703\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 47.1926 - accuracy: 0.7066 - val_loss: 34.4907 - val_accuracy: 0.7406\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 29.0546 - accuracy: 0.7306 - val_loss: 11.3370 - val_accuracy: 0.7945\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 19.2509 - accuracy: 0.7728 - val_loss: 16.6151 - val_accuracy: 0.6938\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 12.5688 - accuracy: 0.7866 - val_loss: 12.0643 - val_accuracy: 0.7448\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 8.2959 - accuracy: 0.7988 - val_loss: 8.1744 - val_accuracy: 0.7825\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 5.2405 - accuracy: 0.8159 - val_loss: 3.7003 - val_accuracy: 0.8012\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 3.2981 - accuracy: 0.8249 - val_loss: 3.2219 - val_accuracy: 0.7976\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.4702 - accuracy: 0.8343 - val_loss: 2.0532 - val_accuracy: 0.8001\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.9261 - accuracy: 0.8262 - val_loss: 1.3676 - val_accuracy: 0.8243\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.2332 - accuracy: 0.8457 - val_loss: 0.9412 - val_accuracy: 0.8410\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.9405 - accuracy: 0.8436 - val_loss: 1.1448 - val_accuracy: 0.8150\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.7357 - accuracy: 0.8487 - val_loss: 0.6861 - val_accuracy: 0.8471\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.5602 - accuracy: 0.8652 - val_loss: 0.5433 - val_accuracy: 0.8595\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4748 - accuracy: 0.8663 - val_loss: 0.7300 - val_accuracy: 0.8358\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4246 - accuracy: 0.8697 - val_loss: 0.7043 - val_accuracy: 0.8266\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.4090 - accuracy: 0.8706 - val_loss: 0.5738 - val_accuracy: 0.8390\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3644 - accuracy: 0.8791 - val_loss: 0.5068 - val_accuracy: 0.8575\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3191 - accuracy: 0.8925 - val_loss: 0.5066 - val_accuracy: 0.8523\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3275 - accuracy: 0.8867 - val_loss: 0.4605 - val_accuracy: 0.8625\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3057 - accuracy: 0.8947 - val_loss: 0.4468 - val_accuracy: 0.8644\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2823 - accuracy: 0.8979 - val_loss: 0.4971 - val_accuracy: 0.8512\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2834 - accuracy: 0.8989 - val_loss: 0.5395 - val_accuracy: 0.8430\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2729 - accuracy: 0.9012 - val_loss: 0.4552 - val_accuracy: 0.8672\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2561 - accuracy: 0.9087 - val_loss: 0.5220 - val_accuracy: 0.8500\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2504 - accuracy: 0.9089 - val_loss: 0.4372 - val_accuracy: 0.8716\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2397 - accuracy: 0.9115 - val_loss: 0.4508 - val_accuracy: 0.8727\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2439 - accuracy: 0.9109 - val_loss: 0.4607 - val_accuracy: 0.8642\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2286 - accuracy: 0.9142 - val_loss: 0.4942 - val_accuracy: 0.8670\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2287 - accuracy: 0.9160 - val_loss: 0.5099 - val_accuracy: 0.8572\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2150 - accuracy: 0.9204 - val_loss: 0.4837 - val_accuracy: 0.8639\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2156 - accuracy: 0.9210 - val_loss: 0.5133 - val_accuracy: 0.8679\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2169 - accuracy: 0.9210 - val_loss: 0.5078 - val_accuracy: 0.8623\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2064 - accuracy: 0.9227 - val_loss: 0.4744 - val_accuracy: 0.8686\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1975 - accuracy: 0.9256 - val_loss: 0.5732 - val_accuracy: 0.8513\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.2069 - accuracy: 0.9212 - val_loss: 0.5118 - val_accuracy: 0.8691\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1941 - accuracy: 0.9268 - val_loss: 0.5484 - val_accuracy: 0.8595\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1919 - accuracy: 0.9278 - val_loss: 0.5277 - val_accuracy: 0.8582\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1876 - accuracy: 0.9306 - val_loss: 0.5473 - val_accuracy: 0.8575\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1994 - accuracy: 0.9251 - val_loss: 0.5098 - val_accuracy: 0.8676\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1771 - accuracy: 0.9335 - val_loss: 0.5372 - val_accuracy: 0.8680\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1857 - accuracy: 0.9294 - val_loss: 0.5283 - val_accuracy: 0.8664\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1737 - accuracy: 0.9351 - val_loss: 0.5256 - val_accuracy: 0.8699\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1808 - accuracy: 0.9327 - val_loss: 0.5507 - val_accuracy: 0.8704\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1762 - accuracy: 0.9341 - val_loss: 0.5332 - val_accuracy: 0.8683\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1841 - accuracy: 0.9328 - val_loss: 0.5509 - val_accuracy: 0.8620\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1698 - accuracy: 0.9369 - val_loss: 0.5526 - val_accuracy: 0.8693\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1656 - accuracy: 0.9384 - val_loss: 0.5351 - val_accuracy: 0.8653\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1572 - accuracy: 0.9409 - val_loss: 0.5873 - val_accuracy: 0.8626\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1746 - accuracy: 0.9340 - val_loss: 0.5670 - val_accuracy: 0.8670\n",
            "rmsprop505000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 354560.7465 - accuracy: 0.1020 - val_loss: 123369.0437 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 64595.9793 - accuracy: 0.1004 - val_loss: 74854.2840 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 61296.5838 - accuracy: 0.0986 - val_loss: 102822.8023 - val_accuracy: 0.1000\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 59090.0749 - accuracy: 0.1018 - val_loss: 56040.4586 - val_accuracy: 0.1000\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 52798.0157 - accuracy: 0.1010 - val_loss: 6961.7347 - val_accuracy: 0.1000\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 51051.5903 - accuracy: 0.1008 - val_loss: 46054.3590 - val_accuracy: 0.1000\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 46000.1661 - accuracy: 0.0975 - val_loss: 103892.2918 - val_accuracy: 0.1000\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 44607.6274 - accuracy: 0.0996 - val_loss: 12774.5459 - val_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 42412.4843 - accuracy: 0.0988 - val_loss: 99562.4027 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 43753.7871 - accuracy: 0.1006 - val_loss: 65717.9449 - val_accuracy: 0.1000\n",
            "sgd10500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 21.5144 - accuracy: 0.1307 - val_loss: 2.2712 - val_accuracy: 0.1693\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.2376 - accuracy: 0.1873 - val_loss: 2.0709 - val_accuracy: 0.2895\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.0002 - accuracy: 0.3603 - val_loss: 1.9013 - val_accuracy: 0.4478\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 2.1065 - accuracy: 0.2984 - val_loss: 2.0236 - val_accuracy: 0.3604\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.8628 - accuracy: 0.4238 - val_loss: 1.6222 - val_accuracy: 0.5184\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 1.6238 - accuracy: 0.5292 - val_loss: 1.4358 - val_accuracy: 0.5874\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 1.4442 - accuracy: 0.5857 - val_loss: 1.1973 - val_accuracy: 0.6517\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 1.2840 - accuracy: 0.6330 - val_loss: 1.1522 - val_accuracy: 0.6832\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 1.1559 - accuracy: 0.6672 - val_loss: 1.2993 - val_accuracy: 0.6700\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 1.0783 - accuracy: 0.6906 - val_loss: 1.5254 - val_accuracy: 0.6362\n",
            "sgd101000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 839225.8903 - accuracy: 0.1124 - val_loss: 29421.5342 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 27416.5475 - accuracy: 0.0997 - val_loss: 3227.2358 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 26160.2798 - accuracy: 0.1007 - val_loss: 12046.5020 - val_accuracy: 0.1000\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 25496.8914 - accuracy: 0.1007 - val_loss: 21047.5703 - val_accuracy: 0.1000\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 24633.2974 - accuracy: 0.1007 - val_loss: 30228.1318 - val_accuracy: 0.1000\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 24227.6616 - accuracy: 0.0980 - val_loss: 39588.3340 - val_accuracy: 0.1000\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 22900.6298 - accuracy: 0.0998 - val_loss: 49124.5156 - val_accuracy: 0.1000\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 26551.1660 - accuracy: 0.1005 - val_loss: 1411.5351 - val_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 26216.7684 - accuracy: 0.0998 - val_loss: 9502.0420 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 24801.1452 - accuracy: 0.0992 - val_loss: 21335.3467 - val_accuracy: 0.1000\n",
            "sgd105000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 69614.6587 - accuracy: 0.1006 - val_loss: 9560.4535 - val_accuracy: 0.1000\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 7595.3426 - accuracy: 0.1008 - val_loss: 10452.7297 - val_accuracy: 0.1000\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 7441.3690 - accuracy: 0.1000 - val_loss: 13522.7514 - val_accuracy: 0.1000\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 7083.1708 - accuracy: 0.0990 - val_loss: 4836.2748 - val_accuracy: 0.1000\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 6414.8187 - accuracy: 0.1005 - val_loss: 9176.1423 - val_accuracy: 0.1000\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 6253.9486 - accuracy: 0.1001 - val_loss: 3820.8417 - val_accuracy: 0.1000\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5934.3899 - accuracy: 0.1012 - val_loss: 10574.2956 - val_accuracy: 0.1000\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5959.9140 - accuracy: 0.1017 - val_loss: 5061.6078 - val_accuracy: 0.1000\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5820.7818 - accuracy: 0.0987 - val_loss: 3230.7917 - val_accuracy: 0.1000\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5723.1601 - accuracy: 0.0996 - val_loss: 2298.3214 - val_accuracy: 0.1000\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5724.3829 - accuracy: 0.1027 - val_loss: 3323.7506 - val_accuracy: 0.1000\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5721.3298 - accuracy: 0.1015 - val_loss: 3364.2440 - val_accuracy: 0.1000\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5677.3727 - accuracy: 0.1005 - val_loss: 3941.2135 - val_accuracy: 0.1000\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5738.4916 - accuracy: 0.0989 - val_loss: 4033.6050 - val_accuracy: 0.1000\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5707.7560 - accuracy: 0.1002 - val_loss: 5197.4253 - val_accuracy: 0.1000\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5728.7989 - accuracy: 0.1024 - val_loss: 4721.9356 - val_accuracy: 0.1000\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5760.5681 - accuracy: 0.0990 - val_loss: 6576.0203 - val_accuracy: 0.1000\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5742.4953 - accuracy: 0.0997 - val_loss: 5494.2048 - val_accuracy: 0.1000\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5624.7718 - accuracy: 0.1006 - val_loss: 7474.5465 - val_accuracy: 0.1000\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5756.6755 - accuracy: 0.0997 - val_loss: 5404.5329 - val_accuracy: 0.1000\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5772.5006 - accuracy: 0.1005 - val_loss: 4814.4340 - val_accuracy: 0.1000\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5610.3247 - accuracy: 0.1009 - val_loss: 6757.4327 - val_accuracy: 0.1000\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5664.4317 - accuracy: 0.1001 - val_loss: 7904.5757 - val_accuracy: 0.1000\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5774.7050 - accuracy: 0.0989 - val_loss: 7230.3070 - val_accuracy: 0.1000\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5699.2311 - accuracy: 0.0995 - val_loss: 7450.9219 - val_accuracy: 0.1000\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5574.9258 - accuracy: 0.1005 - val_loss: 8155.9477 - val_accuracy: 0.1000\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5586.3650 - accuracy: 0.1009 - val_loss: 8306.0176 - val_accuracy: 0.1000\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5491.1053 - accuracy: 0.1006 - val_loss: 11271.9888 - val_accuracy: 0.1000\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5714.3313 - accuracy: 0.0990 - val_loss: 10323.9774 - val_accuracy: 0.1000\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 5659.5411 - accuracy: 0.0994 - val_loss: 10050.7386 - val_accuracy: 0.1000\n",
            "sgd30500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 629.1314 - accuracy: 0.1032 - val_loss: 10.6230 - val_accuracy: 0.1000\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 8.6902 - accuracy: 0.0996 - val_loss: 13.8509 - val_accuracy: 0.1000\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 8.2697 - accuracy: 0.0998 - val_loss: 5.3557 - val_accuracy: 0.1000\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 7.8593 - accuracy: 0.1019 - val_loss: 8.7040 - val_accuracy: 0.1000\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 7.5107 - accuracy: 0.0982 - val_loss: 5.2609 - val_accuracy: 0.1000\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 7.0518 - accuracy: 0.1001 - val_loss: 5.6793 - val_accuracy: 0.1000\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 7.0381 - accuracy: 0.1003 - val_loss: 5.2969 - val_accuracy: 0.1000\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.3862 - accuracy: 0.1012 - val_loss: 3.0592 - val_accuracy: 0.1000\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.6389 - accuracy: 0.1003 - val_loss: 9.3586 - val_accuracy: 0.1000\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.9291 - accuracy: 0.1015 - val_loss: 4.4273 - val_accuracy: 0.1000\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.5694 - accuracy: 0.1008 - val_loss: 3.8072 - val_accuracy: 0.1000\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.2684 - accuracy: 0.1018 - val_loss: 13.5427 - val_accuracy: 0.1000\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.7882 - accuracy: 0.1005 - val_loss: 8.1242 - val_accuracy: 0.1000\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.6092 - accuracy: 0.1009 - val_loss: 3.3361 - val_accuracy: 0.1000\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.9283 - accuracy: 0.0998 - val_loss: 2.9103 - val_accuracy: 0.1000\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.5523 - accuracy: 0.1020 - val_loss: 5.8268 - val_accuracy: 0.1000\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.5299 - accuracy: 0.1005 - val_loss: 3.4247 - val_accuracy: 0.1000\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 5.3460 - accuracy: 0.0954 - val_loss: 12.3353 - val_accuracy: 0.1000\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.9191 - accuracy: 0.0997 - val_loss: 7.0834 - val_accuracy: 0.1000\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.9457 - accuracy: 0.1001 - val_loss: 14.2530 - val_accuracy: 0.1000\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 5.2243 - accuracy: 0.0993 - val_loss: 2.8203 - val_accuracy: 0.1000\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.1189 - accuracy: 0.0977 - val_loss: 8.9370 - val_accuracy: 0.1000\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.4299 - accuracy: 0.0994 - val_loss: 10.5923 - val_accuracy: 0.1000\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.4673 - accuracy: 0.1010 - val_loss: 2.8280 - val_accuracy: 0.1000\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 6.7081 - accuracy: 0.0996 - val_loss: 3.3363 - val_accuracy: 0.1000\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.1649 - accuracy: 0.0989 - val_loss: 4.2989 - val_accuracy: 0.1000\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.8318 - accuracy: 0.0997 - val_loss: 3.7513 - val_accuracy: 0.1000\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 5.9170 - accuracy: 0.0991 - val_loss: 8.1464 - val_accuracy: 0.1000\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 5.4370 - accuracy: 0.0993 - val_loss: 3.5077 - val_accuracy: 0.1000\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 6.0531 - accuracy: 0.0978 - val_loss: 10.1619 - val_accuracy: 0.1000\n",
            "sgd301000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 164.8281 - accuracy: 0.1042 - val_loss: 2.3117 - val_accuracy: 0.1011\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3058 - accuracy: 0.0984 - val_loss: 2.3023 - val_accuracy: 0.0836\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3043 - accuracy: 0.0941 - val_loss: 2.3021 - val_accuracy: 0.0790\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3017 - accuracy: 0.0956 - val_loss: 2.3024 - val_accuracy: 0.1108\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3022 - accuracy: 0.0981 - val_loss: 2.3030 - val_accuracy: 0.0814\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3012 - accuracy: 0.0962 - val_loss: 2.3004 - val_accuracy: 0.1169\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3001 - accuracy: 0.1081 - val_loss: 2.2999 - val_accuracy: 0.0854\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3031 - accuracy: 0.0975 - val_loss: 2.3056 - val_accuracy: 0.1019\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3042 - accuracy: 0.0990 - val_loss: 2.3048 - val_accuracy: 0.1004\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3017 - accuracy: 0.1000 - val_loss: 2.3045 - val_accuracy: 0.1009\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3010 - accuracy: 0.1009 - val_loss: 2.3006 - val_accuracy: 0.1138\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2987 - accuracy: 0.1042 - val_loss: 2.3008 - val_accuracy: 0.0933\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2987 - accuracy: 0.1060 - val_loss: 2.2967 - val_accuracy: 0.1194\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3015 - accuracy: 0.1060 - val_loss: 2.3021 - val_accuracy: 0.1128\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2959 - accuracy: 0.1164 - val_loss: 2.2977 - val_accuracy: 0.0950\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 2.2956 - accuracy: 0.1058 - val_loss: 2.2920 - val_accuracy: 0.1111\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2938 - accuracy: 0.1087 - val_loss: 2.2911 - val_accuracy: 0.0970\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.3010 - accuracy: 0.1053 - val_loss: 2.2932 - val_accuracy: 0.1441\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2921 - accuracy: 0.1316 - val_loss: 2.2901 - val_accuracy: 0.1336\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2932 - accuracy: 0.1107 - val_loss: 2.2870 - val_accuracy: 0.1256\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2853 - accuracy: 0.1327 - val_loss: 2.2830 - val_accuracy: 0.1397\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2872 - accuracy: 0.1214 - val_loss: 2.2966 - val_accuracy: 0.1189\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2849 - accuracy: 0.1226 - val_loss: 2.2847 - val_accuracy: 0.1265\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 2.2819 - accuracy: 0.1204 - val_loss: 2.2752 - val_accuracy: 0.1418\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2784 - accuracy: 0.1339 - val_loss: 2.2691 - val_accuracy: 0.1542\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2641 - accuracy: 0.1701 - val_loss: 2.2557 - val_accuracy: 0.1742\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2419 - accuracy: 0.1923 - val_loss: 2.2279 - val_accuracy: 0.2031\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.1969 - accuracy: 0.2306 - val_loss: 2.2088 - val_accuracy: 0.2233\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.1926 - accuracy: 0.2495 - val_loss: 2.2123 - val_accuracy: 0.2127\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 2.2922 - accuracy: 0.1442 - val_loss: 2.3009 - val_accuracy: 0.0985\n",
            "sgd305000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 3.4466 - accuracy: 0.7428 - val_loss: 0.5406 - val_accuracy: 0.8106\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.4810 - accuracy: 0.8322 - val_loss: 0.4775 - val_accuracy: 0.8339\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.4415 - accuracy: 0.8440 - val_loss: 0.4654 - val_accuracy: 0.8355\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.4171 - accuracy: 0.8520 - val_loss: 0.4310 - val_accuracy: 0.8506\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.4006 - accuracy: 0.8566 - val_loss: 0.4532 - val_accuracy: 0.8422\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3934 - accuracy: 0.8590 - val_loss: 0.4281 - val_accuracy: 0.8509\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3809 - accuracy: 0.8623 - val_loss: 0.4873 - val_accuracy: 0.8232\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3732 - accuracy: 0.8666 - val_loss: 0.4162 - val_accuracy: 0.8518\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3690 - accuracy: 0.8666 - val_loss: 0.4351 - val_accuracy: 0.8470\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3566 - accuracy: 0.8715 - val_loss: 0.3995 - val_accuracy: 0.8629\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3548 - accuracy: 0.8721 - val_loss: 0.4295 - val_accuracy: 0.8520\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3584 - accuracy: 0.8705 - val_loss: 0.4019 - val_accuracy: 0.8603\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3484 - accuracy: 0.8732 - val_loss: 0.3985 - val_accuracy: 0.8617\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3434 - accuracy: 0.8758 - val_loss: 0.3856 - val_accuracy: 0.8681\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3419 - accuracy: 0.8762 - val_loss: 0.3913 - val_accuracy: 0.8643\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3376 - accuracy: 0.8766 - val_loss: 0.4052 - val_accuracy: 0.8582\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3348 - accuracy: 0.8782 - val_loss: 0.3946 - val_accuracy: 0.8651\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3370 - accuracy: 0.8778 - val_loss: 0.3949 - val_accuracy: 0.8638\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3297 - accuracy: 0.8804 - val_loss: 0.4170 - val_accuracy: 0.8559\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3289 - accuracy: 0.8804 - val_loss: 0.3909 - val_accuracy: 0.8669\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3252 - accuracy: 0.8817 - val_loss: 0.4113 - val_accuracy: 0.8571\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3180 - accuracy: 0.8839 - val_loss: 0.3974 - val_accuracy: 0.8666\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3221 - accuracy: 0.8835 - val_loss: 0.4027 - val_accuracy: 0.8614\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3150 - accuracy: 0.8842 - val_loss: 0.3831 - val_accuracy: 0.8708\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3191 - accuracy: 0.8821 - val_loss: 0.3849 - val_accuracy: 0.8709\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3148 - accuracy: 0.8859 - val_loss: 0.3932 - val_accuracy: 0.8692\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3093 - accuracy: 0.8875 - val_loss: 0.4170 - val_accuracy: 0.8583\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3062 - accuracy: 0.8874 - val_loss: 0.3929 - val_accuracy: 0.8672\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3062 - accuracy: 0.8880 - val_loss: 0.3927 - val_accuracy: 0.8690\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3041 - accuracy: 0.8879 - val_loss: 0.3983 - val_accuracy: 0.8679\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3009 - accuracy: 0.8897 - val_loss: 0.3983 - val_accuracy: 0.8681\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3023 - accuracy: 0.8890 - val_loss: 0.3765 - val_accuracy: 0.8722\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2997 - accuracy: 0.8901 - val_loss: 0.3768 - val_accuracy: 0.8733\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2907 - accuracy: 0.8925 - val_loss: 0.3917 - val_accuracy: 0.8698\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2977 - accuracy: 0.8905 - val_loss: 0.3818 - val_accuracy: 0.8760\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2931 - accuracy: 0.8914 - val_loss: 0.3866 - val_accuracy: 0.8711\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2903 - accuracy: 0.8935 - val_loss: 0.3865 - val_accuracy: 0.8732\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2878 - accuracy: 0.8948 - val_loss: 0.3844 - val_accuracy: 0.8724\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2849 - accuracy: 0.8947 - val_loss: 0.3769 - val_accuracy: 0.8753\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2819 - accuracy: 0.8961 - val_loss: 0.3952 - val_accuracy: 0.8664\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2798 - accuracy: 0.8983 - val_loss: 0.3822 - val_accuracy: 0.8716\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2760 - accuracy: 0.8981 - val_loss: 0.3809 - val_accuracy: 0.8740\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2756 - accuracy: 0.8989 - val_loss: 0.4003 - val_accuracy: 0.8715\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2739 - accuracy: 0.8991 - val_loss: 0.3744 - val_accuracy: 0.8725\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2725 - accuracy: 0.9001 - val_loss: 0.3960 - val_accuracy: 0.8704\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2707 - accuracy: 0.9011 - val_loss: 0.3749 - val_accuracy: 0.8776\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2719 - accuracy: 0.8993 - val_loss: 0.3790 - val_accuracy: 0.8765\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2680 - accuracy: 0.9013 - val_loss: 0.3863 - val_accuracy: 0.8746\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2640 - accuracy: 0.9031 - val_loss: 0.3875 - val_accuracy: 0.8727\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2642 - accuracy: 0.9021 - val_loss: 0.3812 - val_accuracy: 0.8743\n",
            "sgd50500 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 548791.7966 - accuracy: 0.1000 - val_loss: 157374.1641 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 94173.5736 - accuracy: 0.0987 - val_loss: 4492.0916 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 91925.8224 - accuracy: 0.1019 - val_loss: 91485.8383 - val_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 86869.2539 - accuracy: 0.1011 - val_loss: 64906.8133 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 92180.3477 - accuracy: 0.1004 - val_loss: 108096.2195 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 88960.4344 - accuracy: 0.0981 - val_loss: 32613.0959 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 86091.9262 - accuracy: 0.0995 - val_loss: 160324.3984 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 88437.3895 - accuracy: 0.1024 - val_loss: 94761.1219 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 85781.2143 - accuracy: 0.1002 - val_loss: 51325.1516 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 83717.7790 - accuracy: 0.0993 - val_loss: 24393.4939 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 81978.6893 - accuracy: 0.1022 - val_loss: 10231.1850 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 81456.7462 - accuracy: 0.0985 - val_loss: 16615.3842 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 81393.4031 - accuracy: 0.0994 - val_loss: 32497.7107 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 78511.6297 - accuracy: 0.1010 - val_loss: 82214.9383 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 76293.7100 - accuracy: 0.0989 - val_loss: 136961.5609 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 77346.5404 - accuracy: 0.0998 - val_loss: 24392.5297 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 75330.8500 - accuracy: 0.0988 - val_loss: 114053.9344 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 74157.4320 - accuracy: 0.1003 - val_loss: 57446.3441 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 70958.7750 - accuracy: 0.1017 - val_loss: 12480.9852 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 71027.4010 - accuracy: 0.0993 - val_loss: 11616.6943 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 69897.2192 - accuracy: 0.0990 - val_loss: 153076.6328 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 72154.5086 - accuracy: 0.0995 - val_loss: 134514.8289 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 70942.2479 - accuracy: 0.0984 - val_loss: 133159.5820 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 71907.2474 - accuracy: 0.1000 - val_loss: 122992.8102 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 71835.2902 - accuracy: 0.0978 - val_loss: 108183.7266 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69992.0583 - accuracy: 0.0997 - val_loss: 115099.2750 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 70960.8443 - accuracy: 0.0978 - val_loss: 106510.7773 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 69321.2706 - accuracy: 0.0978 - val_loss: 110032.2664 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 71834.2146 - accuracy: 0.1010 - val_loss: 90903.5398 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69187.2840 - accuracy: 0.0985 - val_loss: 103506.0648 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69361.5241 - accuracy: 0.1011 - val_loss: 105189.2461 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69900.4527 - accuracy: 0.0996 - val_loss: 104815.8070 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69980.1978 - accuracy: 0.0977 - val_loss: 107327.2008 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 70057.4386 - accuracy: 0.1003 - val_loss: 107658.9297 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 70649.9467 - accuracy: 0.0992 - val_loss: 105649.8305 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 70778.5354 - accuracy: 0.0992 - val_loss: 102061.2906 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 69334.8156 - accuracy: 0.1000 - val_loss: 107224.6687 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 68830.4286 - accuracy: 0.0987 - val_loss: 116833.4312 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 70193.3813 - accuracy: 0.0991 - val_loss: 108815.7742 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 68468.5492 - accuracy: 0.0991 - val_loss: 124418.7492 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 68533.6260 - accuracy: 0.1025 - val_loss: 121134.1148 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 68627.6419 - accuracy: 0.1025 - val_loss: 126337.4695 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69809.8049 - accuracy: 0.0994 - val_loss: 125900.0352 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 69052.4397 - accuracy: 0.1016 - val_loss: 119689.6727 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69442.1915 - accuracy: 0.0982 - val_loss: 123592.3758 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 68348.2682 - accuracy: 0.0994 - val_loss: 123216.8242 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69413.2379 - accuracy: 0.0997 - val_loss: 122702.2648 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 69658.0457 - accuracy: 0.0986 - val_loss: 124035.1820 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 68411.8197 - accuracy: 0.1005 - val_loss: 125424.4086 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 67684.5116 - accuracy: 0.1014 - val_loss: 142681.8594 - val_accuracy: 0.1000\n",
            "sgd501000 :  0.884\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 2549594.5779 - accuracy: 0.1041 - val_loss: 35663.6582 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 100367.2142 - accuracy: 0.1001 - val_loss: 87358.1289 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 73345.7199 - accuracy: 0.1002 - val_loss: 173440.4531 - val_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 105659.1675 - accuracy: 0.1000 - val_loss: 68073.4258 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 78614.9534 - accuracy: 0.0989 - val_loss: 162120.0859 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 100029.6627 - accuracy: 0.0997 - val_loss: 52419.3086 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 82307.9323 - accuracy: 0.0986 - val_loss: 147431.4297 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 94465.6862 - accuracy: 0.1001 - val_loss: 40239.3516 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 83395.0392 - accuracy: 0.1003 - val_loss: 136291.4141 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 90712.9787 - accuracy: 0.1004 - val_loss: 31693.3105 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 84702.4427 - accuracy: 0.1013 - val_loss: 128892.4961 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 87857.0398 - accuracy: 0.1009 - val_loss: 26708.4521 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 86903.6190 - accuracy: 0.0989 - val_loss: 124815.4180 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 85621.2349 - accuracy: 0.1018 - val_loss: 29836.0049 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 84601.8837 - accuracy: 0.1004 - val_loss: 128334.7305 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 87804.3191 - accuracy: 0.0998 - val_loss: 29811.0713 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 85351.7108 - accuracy: 0.0990 - val_loss: 128665.8906 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 88445.0968 - accuracy: 0.0996 - val_loss: 30263.8975 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 82035.4559 - accuracy: 0.1011 - val_loss: 129467.1406 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 87314.2283 - accuracy: 0.1000 - val_loss: 32036.7158 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 82547.9833 - accuracy: 0.1008 - val_loss: 131592.1641 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 89447.5194 - accuracy: 0.1000 - val_loss: 35135.0840 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 80732.0858 - accuracy: 0.1008 - val_loss: 135040.8047 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 89829.4732 - accuracy: 0.1011 - val_loss: 39596.1406 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 79819.8823 - accuracy: 0.1000 - val_loss: 139873.3516 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 91434.0132 - accuracy: 0.0998 - val_loss: 45895.3633 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 74232.7518 - accuracy: 0.1005 - val_loss: 150362.1484 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 95147.3281 - accuracy: 0.0988 - val_loss: 57318.0859 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 71196.4437 - accuracy: 0.1005 - val_loss: 159475.9531 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 97860.0552 - accuracy: 0.0998 - val_loss: 67516.7617 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 67285.6795 - accuracy: 0.1025 - val_loss: 125368.8516 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 98169.5628 - accuracy: 0.1011 - val_loss: 84001.9844 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 73270.9987 - accuracy: 0.1009 - val_loss: 37682.6113 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 93143.1500 - accuracy: 0.1000 - val_loss: 97628.1602 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 76875.6768 - accuracy: 0.1007 - val_loss: 9924.2373 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 85796.9343 - accuracy: 0.1020 - val_loss: 112209.2148 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 82826.0392 - accuracy: 0.1007 - val_loss: 23681.6475 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 79479.8448 - accuracy: 0.1002 - val_loss: 128452.5117 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 86641.5933 - accuracy: 0.0993 - val_loss: 41185.9551 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 74077.7303 - accuracy: 0.1022 - val_loss: 143957.3125 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 92341.7419 - accuracy: 0.0994 - val_loss: 57219.4199 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 68789.0094 - accuracy: 0.1004 - val_loss: 162185.3125 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 96530.2275 - accuracy: 0.1016 - val_loss: 76696.2969 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 70967.1831 - accuracy: 0.1008 - val_loss: 44075.0586 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 92498.1419 - accuracy: 0.0999 - val_loss: 96725.5781 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 76585.5776 - accuracy: 0.0984 - val_loss: 14052.1055 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 83187.7719 - accuracy: 0.1004 - val_loss: 118029.4414 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 83271.7128 - accuracy: 0.1006 - val_loss: 36408.9355 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 68885.7789 - accuracy: 0.0992 - val_loss: 150243.1719 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 93787.8567 - accuracy: 0.1009 - val_loss: 66321.0547 - val_accuracy: 0.1000\n",
            "sgd505000 :  0.884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RHpN_Or5uY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f0f8241f-b0c0-4ac5-bd41-9b9c202957c1"
      },
      "source": [
        "print(exp_dict)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'adam10500': 0.884, 'adam101000': 0.884, 'adam105000': 0.884, 'adam30500': 0.884, 'adam301000': 0.884, 'adam305000': 0.884, 'adam50500': 0.884, 'adam501000': 0.884, 'adam505000': 0.884, 'rmsprop10500': 0.884, 'rmsprop101000': 0.884, 'rmsprop105000': 0.884, 'rmsprop30500': 0.884, 'rmsprop301000': 0.884, 'rmsprop305000': 0.884, 'rmsprop50500': 0.884, 'rmsprop501000': 0.884, 'rmsprop505000': 0.884, 'sgd10500': 0.884, 'sgd101000': 0.884, 'sgd105000': 0.884, 'sgd30500': 0.884, 'sgd301000': 0.884, 'sgd305000': 0.884, 'sgd50500': 0.884, 'sgd501000': 0.884, 'sgd505000': 0.884}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}