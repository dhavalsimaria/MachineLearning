{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Industry Grade Project - Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhavalsimaria/MachineLearning/blob/master/NITW/DL%20%26%20AI/Industry_Grade_Project_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7CCJZKdcC2",
        "colab_type": "text"
      },
      "source": [
        "# Building a Chatbot from Scratch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsR2PuNPdcC5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##### In this project we will build a chatbot from scratch using the corenell University's Movie Dialogue corpus.\n",
        "##### We will be using a deep learning based architecture with the main components as a lstm based encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7b5o0oxdcC7",
        "colab_type": "code",
        "outputId": "db694fd9-3321-477c-ddad-12ecb46e6310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFN5fXsdcDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import nltk\n",
        "import numpy\n",
        "import sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IQF3dSidcDI",
        "colab_type": "text"
      },
      "source": [
        "Please make sure that the version of the respective packages are met to the requirement. **I have commented out this code as versions used in colab currently are higher than mentioned. Same was confirmed with Edureka team earlier.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCL0434GdcDK",
        "colab_type": "code",
        "outputId": "00142f63-920e-4813-a7ad-63b221b25d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''assert keras.__version__=='2.1.2'\n",
        "assert nltk.__version__=='3.4.1'\n",
        "assert sklearn.__version__=='0.21.2'\n",
        "assert numpy.__version__=='1.12.1'\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"assert keras.__version__=='2.1.2'\\nassert nltk.__version__=='3.4.1'\\nassert sklearn.__version__=='0.21.2'\\nassert numpy.__version__=='1.12.1'\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv38ReVtdcDO",
        "colab_type": "text"
      },
      "source": [
        "Download the glove model available at https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Specification : Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXuwJNpGdcDQ",
        "colab_type": "text"
      },
      "source": [
        "you can download it with 'wget' or can directly put the embedding zip file inside 'embedding_data' folder and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHx1FnytdcDU",
        "colab_type": "code",
        "outputId": "28ff9d04-458c-4fdc-ac0d-1ddb4be18413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "! curl -O http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1449M  100 1449M    0     0  2116k      0  0:11:41  0:11:41 --:--:-- 2790k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16MQ-fhzOuWJ",
        "colab_type": "code",
        "outputId": "9173cb96-1c77-4c5f-e332-83ecef5d844f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "! unzip glove.twitter.27B.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXNV-PBFmTw6",
        "colab_type": "text"
      },
      "source": [
        "Download the Cornell Movie Dialog dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__3xsvNEmmGL",
        "colab_type": "code",
        "outputId": "07c83a4c-4abc-449b-abbf-0bd4af3288d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!curl -L -O http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9684k  100 9684k    0     0  2273k      0  0:00:04  0:00:04 --:--:-- 2273k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y09NB0XEmr6Q",
        "colab_type": "text"
      },
      "source": [
        "Unzip the Cornell Movie Dialog dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul9iW2sxmvv7",
        "colab_type": "code",
        "outputId": "6a193281-7864-41a5-a41b-db80fc2f9f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!unzip cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJTbG5ToZYVj",
        "colab_type": "text"
      },
      "source": [
        "Define constants. **Some are modified based on folder structure in colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_yG4mV2dcDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = 'cornell'\n",
        "#DATA_PATH = './cornell/movie_lines_cleaned.txt'\n",
        "#GLOVE_MODEL = \"./embedding_data/glove.twitter.27B.100d.txt\"\n",
        "DATA_PATH = 'cornell movie-dialogs corpus/movie_lines.txt'\n",
        "GLOVE_MODEL = \"glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH =  DATA_SET_NAME + '/word-glove-weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YoCF2A8bSoo",
        "colab_type": "text"
      },
      "source": [
        "Function to identify if a given word is whitelisted or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsku9GyddcDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def in_white_list(_word):\n",
        "  for char in _word:\n",
        "        if char in WHITELIST:\n",
        "            return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKA3WnoNdcDk",
        "colab_type": "text"
      },
      "source": [
        "Load the glove word embedding in to a dictionary where the **key** is a unique **word token** and the **value** is a **d** dimension vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ6Q6VpHdcDn",
        "colab_type": "text"
      },
      "source": [
        "# Test-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DtZYF8_dcDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        #vector = np.asarray(values[1:], \"float32\")\n",
        "        vector = np.array([float(val) for val in values[1:]])\n",
        "        _word2embedding[word] = vector\n",
        "    file.close()\n",
        "    return _word2embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdoRZsWEdcDs",
        "colab_type": "code",
        "outputId": "eb6452b1-427c-4103-dac6-46b29af3389f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2embedding = load_glove_vector()\n",
        "len(word2embedding.keys())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1193514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1WwP20dcDw",
        "colab_type": "text"
      },
      "source": [
        "# Check-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xiGzRO1bhV7",
        "colab_type": "text"
      },
      "source": [
        "Here assert statement to modified to have latest number of word2embeddings in glove model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VknKfgmGdcDz",
        "colab_type": "code",
        "outputId": "45d29547-df8e-44e0-d552-9ac01cfa40b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#assert len(word2embedding.keys())==1193513\n",
        "assert len(word2embedding.keys())==1193514\n",
        "for key in word2embedding.keys():\n",
        "    try:\n",
        "        assert len(word2embedding[key])==100\n",
        "    except AssertionError:\n",
        "        print (key,len(word2embedding[key]))     "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.32053 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCix18rAdcD7",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkKBqppEdcD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_counter = Counter()\n",
        "lines = open(DATA_PATH, 'rt', encoding='latin1').read().split(' +++$+++ ')\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "prev_words = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvHPzxjPcA01",
        "colab_type": "text"
      },
      "source": [
        "Import NLTK library to tokenize the lines in dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdbBFWOMOlG",
        "colab_type": "code",
        "outputId": "030c6470-3d82-4d91-949c-14fcf693f2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FsdjO_jdcD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for line in lines:\n",
        "    next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
        "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
        "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
        "    if len(prev_words) > 0:\n",
        "        input_texts.append(prev_words)\n",
        "        target_words = next_words[:]\n",
        "        target_words.insert(0, 'start')\n",
        "        target_words.append('end')\n",
        "        for w in target_words:\n",
        "            target_counter[w] += 1\n",
        "        target_texts.append(target_words)\n",
        "    prev_words = next_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcYFBgUIdcEF",
        "colab_type": "text"
      },
      "source": [
        "Filter the conversations till max word length and convert the dialogues pairs into input text and target texts. Put **start** and **end** token to recognise the beginning and end of the sentence token.\n",
        "\n",
        "## Let's see some of the training examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiCxfQtBdcEG",
        "colab_type": "code",
        "outputId": "052dd542-d4fa-426d-d1c7-b4b6469fdeb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
        "    if idx > 10:\n",
        "        break\n",
        "    print([input_words, target_words])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['l1045'], ['start', 'u0', 'end']]\n",
            "[['u0'], ['start', 'm0', 'end']]\n",
            "[['m0'], ['start', 'bianca', 'end']]\n",
            "[['bianca'], ['start', 'they', 'do', 'not', '!', 'l1044', 'end']]\n",
            "[['they', 'do', 'not', '!', 'l1044'], ['start', 'u2', 'end']]\n",
            "[['u2'], ['start', 'm0', 'end']]\n",
            "[['m0'], ['start', 'cameron', 'end']]\n",
            "[['cameron'], ['start', 'they', 'do', 'to', '!', 'l985', 'end']]\n",
            "[['they', 'do', 'to', '!', 'l985'], ['start', 'u0', 'end']]\n",
            "[['u0'], ['start', 'm0', 'end']]\n",
            "[['m0'], ['start', 'bianca', 'end']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMUQBrgOcKbS",
        "colab_type": "text"
      },
      "source": [
        "Import **OS** library to create directory to hold the Cornell movie dialogue dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv9GcBjNQ-C3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir(DATA_SET_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKxizS6dcEL",
        "colab_type": "text"
      },
      "source": [
        "### Create two dictionaries \n",
        "<ol>\n",
        "<li>target_word2id\n",
        "<li>target_id2word\n",
        "</ol>\n",
        "and save it as NumPy file format in the disk.\n",
        "<p>\n",
        "<strong>NOTE:</strong> The ids should start from 1 beacause <strong>0</strong> is reserved for <strong>'unknown'</strong> tokens.\n",
        "Make sure you cosider only the <strong>most common</strong> tokens with <strong>MAX_VOCAB_SIZE</strong> defined above.\n",
        "\n",
        "Most common refers to tokens with higher frequency. \n",
        "</p>\n",
        "<strong>Help:</strong>\n",
        "<ol>\n",
        "<li>Use the target_counter which have the token counts.  \n",
        "<li>Use target_counter.most_common(MAX_VOCAB_SIZE) to filter common tokens\n",
        "    </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6oco8qdcEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_word2idx = dict()\n",
        "\n",
        "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
        "  target_word2idx[word[0]] = idx + 1\n",
        "\n",
        "''''if 'unknown' not in target_word2idx:\n",
        "    target_word2idx['unknown'] = 0'''\n",
        "\n",
        "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
        "\n",
        "num_decoder_tokens = len(target_idx2word) + 1\n",
        "\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-word2idx.npy', target_word2idx)\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-idx2word.npy', target_idx2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PzuUg4zdcER",
        "colab_type": "text"
      },
      "source": [
        "# Check-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7pikaJfdcEU",
        "colab_type": "code",
        "outputId": "112b6599-d356-48c5-f355-94753301da8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(len (target_word2idx.keys()))\n",
        "print(len (target_idx2word.keys()))\n",
        "print(MAX_VOCAB_SIZE+1)\n",
        "#assert len (target_word2idx.keys())==len (target_idx2word.keys())==MAX_VOCAB_SIZE+1\n",
        "assert len (target_word2idx.keys())==len (target_idx2word.keys())==MAX_VOCAB_SIZE"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "10000\n",
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mw-Ly2xdcEc",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the input data with embedding\n",
        "The input data is a list of lists \n",
        "<ol>\n",
        "<li> First list is a list of sentences\n",
        "<li> Each sentence is a list of words\n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBmG1ea4dcEc",
        "colab_type": "code",
        "outputId": "92ea659a-cce8-4425-82d4-fae28f6da049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_texts_word2em = []\n",
        "encoder_max_seq_length = 0\n",
        "decoder_max_seq_length = 0\n",
        "\n",
        "for input_words, target_words in zip(input_texts, target_texts):\n",
        "    encoder_input_wids = []\n",
        "    for w in input_words:\n",
        "      \n",
        "        embeddings = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "        if w in word2embedding:\n",
        "          embeddings = word2embedding[w]\n",
        "        encoder_input_wids.append(embeddings)\n",
        "\n",
        "\n",
        "    input_texts_word2em.append(encoder_input_wids)\n",
        "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
        "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
        "\n",
        "context = dict()\n",
        "context['num_decoder_tokens'] = num_decoder_tokens\n",
        "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
        "context['decoder_max_seq_length'] = decoder_max_seq_length\n",
        "\n",
        "print(context)\n",
        "np.save( DATA_SET_NAME + '/word-glove-context.npy', context)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_decoder_tokens': 10001, 'encoder_max_seq_length': 40, 'decoder_max_seq_length': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8IJeZVkdcEg",
        "colab_type": "text"
      },
      "source": [
        "# Check-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXaPOQlddcEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_text,input_text_embed in zip (input_texts,range(len(input_texts_word2em))):\n",
        "    assert (len(input_text)==len(input_texts_word2em[input_text_embed]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXh-5WEUdcEn",
        "colab_type": "text"
      },
      "source": [
        "# Generate Training data per batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvg8LBt-dcEo",
        "colab_type": "text"
      },
      "source": [
        "generate_batch takes input embedding data (input_word2em_data) and target text data (target_texts) and returns trainable X and Y.\n",
        "X is a list of [X1,X2]\n",
        "where \n",
        "X1 is encoder_input_data_batch( which is created by putting the word embedding(glove vector) of the input tokens) padded in to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "X2 is decoder_input_data_batch which is created by putting the word embedding(glove vector) of the target_words tokens and padding it to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "Y is decoder_target_data_batch which is in shape of (BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens)\n",
        "which signifies for each target token text  in the batch we have an option of any token from the vocabularu to be the next predicted word "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37R_9qpHdcEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(input_word2em_data, output_text_data):\n",
        "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
        "    while True:\n",
        "        for batchIdx in range(0, num_batches):\n",
        "            start = batchIdx * BATCH_SIZE\n",
        "            end = (batchIdx + 1) * BATCH_SIZE\n",
        "            encoder_input_data_batch = pad_sequences(input_word2em_data[start:end], encoder_max_seq_length)\n",
        "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
        "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE))\n",
        "            for lineIdx, target_words in enumerate(output_text_data[start:end]):\n",
        "              for idx, w in enumerate(target_words):\n",
        "                #w2idx = target_word2idx['unknown']\n",
        "                if w in target_word2idx:\n",
        "                  w2idx = target_word2idx[w]\n",
        "                if w in word2embedding:\n",
        "                  decoder_input_data_batch[lineIdx, idx, :] = word2embedding[w]\n",
        "                if idx > 0:\n",
        "                  decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
        "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjnjiyidcEt",
        "colab_type": "text"
      },
      "source": [
        "# Check-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezag0feRdcEu",
        "colab_type": "code",
        "outputId": "a32dfd59-d9c8-4956-c670-c4a321fb6848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "train_gen = generate_batch(X_train, Y_train)\n",
        "test_gen = generate_batch(X_test, Y_test)\n",
        "\n",
        "for i,j in train_gen:\n",
        "    assert i[0].shape==(BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape==(BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape==(BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "\n",
        "print ('Test Case 4 Passes!')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Case 4 Passes!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8VfVTm4dcE6",
        "colab_type": "text"
      },
      "source": [
        "# Test-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUJbRP9SdcE8",
        "colab_type": "text"
      },
      "source": [
        "<ol>\n",
        "<li> Step 1: Use a LSTM encoder to get input words encoded in the form of (encoder outputs, encoder hidden state, encoder context) from input words\n",
        "<li> Step 2:  Use a LSTM decoder to get target words encoded in the form of (decoder outputs, decoder hidden state, decoder context) from target words. Use encoder hidden states and encoder context (represents input memory) as initial state .\n",
        "<li> Step 3: Use a dense layer to predict the next token out of the vocabulary given decoder output generated by Step 2.\n",
        "<li> Step 4: Use loss ='categorical_crossentropy' and optimizer='rmsprop'\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU974rtIdcE9",
        "colab_type": "code",
        "outputId": "735bde62-e91a-4267-94c6-d608bd85813a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "json = model.to_json()\n",
        "#open('models/' + DATA_SET_NAME + '/word-glove-architecture.json', 'w').write(json)\n",
        "open(DATA_SET_NAME + '/word-glove-architecture.json', 'w').write(json)\n",
        "\n",
        "'''\n",
        "Here I have reduced the size by 1000th part to get a complete execution in Google Colab.\n",
        "When I use entire X_train to fit the model, Google Colab gets disconnected after sometime without completing all the epochs.\n",
        "'''\n",
        "train_num_batches = len(X_train)/1000       \n",
        "test_num_batches = len(X_test)/1000\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath = WEIGHT_FILE_PATH, save_best_only=True)\n",
        "\n",
        "model.fit_generator(generator=train_gen, steps_per_epoch = train_num_batches,\n",
        "                    epochs = NUM_EPOCHS,\n",
        "                    verbose = 1, validation_data = test_gen, \n",
        "                    validation_steps = test_num_batches,\n",
        "                    callbacks = [checkpoint])\n",
        "\n",
        "model.save_weights(WEIGHT_FILE_PATH)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "976/975 [==============================] - 212s 217ms/step - loss: 0.5862 - accuracy: 0.0381 - val_loss: 0.9607 - val_accuracy: 0.0413\n",
            "Epoch 2/10\n",
            "976/975 [==============================] - 206s 212ms/step - loss: 0.5391 - accuracy: 0.0431 - val_loss: 0.6677 - val_accuracy: 0.0436\n",
            "Epoch 3/10\n",
            "976/975 [==============================] - 206s 211ms/step - loss: 0.5207 - accuracy: 0.0446 - val_loss: 0.5647 - val_accuracy: 0.0451\n",
            "Epoch 4/10\n",
            "976/975 [==============================] - 205s 210ms/step - loss: 0.5194 - accuracy: 0.0452 - val_loss: 0.6502 - val_accuracy: 0.0452\n",
            "Epoch 5/10\n",
            "976/975 [==============================] - 208s 213ms/step - loss: 0.5164 - accuracy: 0.0460 - val_loss: 0.5078 - val_accuracy: 0.0460\n",
            "Epoch 6/10\n",
            "976/975 [==============================] - 206s 211ms/step - loss: 0.5087 - accuracy: 0.0462 - val_loss: 0.4130 - val_accuracy: 0.0474\n",
            "Epoch 7/10\n",
            "976/975 [==============================] - 206s 211ms/step - loss: 0.5042 - accuracy: 0.0463 - val_loss: 0.4220 - val_accuracy: 0.0457\n",
            "Epoch 8/10\n",
            "976/975 [==============================] - 206s 211ms/step - loss: 0.5049 - accuracy: 0.0464 - val_loss: 0.5811 - val_accuracy: 0.0477\n",
            "Epoch 9/10\n",
            "976/975 [==============================] - 205s 210ms/step - loss: 0.5149 - accuracy: 0.0473 - val_loss: 0.4051 - val_accuracy: 0.0475\n",
            "Epoch 10/10\n",
            "976/975 [==============================] - 204s 209ms/step - loss: 0.5131 - accuracy: 0.0473 - val_loss: 0.4089 - val_accuracy: 0.0473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YGeW9DC4g_D4"
      },
      "source": [
        "# Model Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KzWrayDfg-o7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "74189561-bc5a-4b26-af38-4d7037476c03"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png',height=400,width=400)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 400,
              "height": 400
            }
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKnqwC4ndcE4",
        "colab_type": "text"
      },
      "source": [
        "# The Model architecture is explined in the diagram above "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1a13QS9fuow",
        "colab_type": "text"
      },
      "source": [
        "<ol>Riki chatbot Model Architecture can be summarized as follows:\n",
        "<li> Initially, Encoder layer and Decoder layer are created w.r.t Glove embedding size.\n",
        "<li> Encoder LSTM layer encodes the input words in the form of encoder outputs, encoder hidden states and encoder context.\n",
        "<li> Using encoder hidden states and encoder context, Decoder LSTM creates target words in the form of decoder outputs, decoder hiddern states and decoder context.\n",
        "<li> Finally a Dense layer uses the decoder output created in previous step\n",
        "to predict next word in the vocabulary\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNAPfQFdcFG",
        "colab_type": "text"
      },
      "source": [
        "# Check-5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecKi6g5MdcFI",
        "colab_type": "text"
      },
      "source": [
        "Check the model summary should look like this "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2-ZeC66dcFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "0b8236e2-c623-4dc2-bffc-b66f7d29df5d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     (None, None, 100)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     (None, None, 100)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 365568      encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  365568      decoder_inputs[0][0]             \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 10001)  2570257     decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,301,393\n",
            "Trainable params: 3,301,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOTTSdcndcFS",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LnAronEeK_d",
        "colab_type": "text"
      },
      "source": [
        "<ol>I have provided two ways to interact with Riki chatbot:\n",
        "<li> Provide input statement/sentence to reply method of Riki chatbot.(Predict Manually)\n",
        "<li> Use a basic user-interface to provide input statement/sentence\n",
        "to Riki chatbot which internally calls it's reply() method to provide the output.(Predicting with interactive interface)\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY39i9S7d2al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RikiChatBot(object):\n",
        "    model = None\n",
        "    encoder_model = None\n",
        "    decoder_model = None\n",
        "    target_word2idx = None\n",
        "    target_idx2word = None\n",
        "    max_decoder_seq_length = None\n",
        "    max_encoder_seq_length = None\n",
        "    num_decoder_tokens = None\n",
        "    word2em = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word2em = load_glove_vector()\n",
        "        print(len(self.word2em))\n",
        "        print(self.word2em['start'])\n",
        "\n",
        "        self.target_word2idx = np.load(\n",
        "            DATA_SET_NAME + '/word-glove-target-word2idx.npy', allow_pickle=True).item()\n",
        "        self.target_idx2word = np.load(\n",
        "            DATA_SET_NAME + '/word-glove-target-idx2word.npy', allow_pickle=True).item()\n",
        "        context = np.load(DATA_SET_NAME + '/word-glove-context.npy', allow_pickle=True).item()\n",
        "        self.max_encoder_seq_length = context['encoder_max_seq_length']\n",
        "        self.max_decoder_seq_length = context['decoder_max_seq_length']\n",
        "        self.num_decoder_tokens = context['num_decoder_tokens']\n",
        "\n",
        "        encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name=\"encoder_lstm\")\n",
        "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "        encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "        decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        self.model.load_weights(DATA_SET_NAME + '/word-glove-weights.h5')\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    def reply(self, input_text):\n",
        "        input_seq = []\n",
        "        input_emb = []\n",
        "        for word in nltk.word_tokenize(input_text.lower()):\n",
        "            if not in_white_list(word):\n",
        "                continue\n",
        "            emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "            if word in self.word2em:\n",
        "                emb = self.word2em[word]\n",
        "            input_emb.append(emb)\n",
        "        input_seq.append(input_emb)\n",
        "        input_seq = pad_sequences(input_seq, self.max_encoder_seq_length)\n",
        "        states_value = self.encoder_model.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "        target_seq[0, 0, :] = self.word2em['start']\n",
        "        target_text = ''\n",
        "        target_text_len = 0\n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "            sample_word = self.target_idx2word[sample_token_idx]\n",
        "            target_text_len += 1\n",
        "\n",
        "            if sample_word != 'start' and sample_word != 'end':\n",
        "                target_text += ' ' + sample_word\n",
        "\n",
        "            if sample_word == 'end' or target_text_len >= self.max_decoder_seq_length:\n",
        "                terminated = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "            if sample_word in self.word2em:\n",
        "                target_seq[0, 0, :] = self.word2em[sample_word]\n",
        "\n",
        "            states_value = [h, c]\n",
        "        return target_text.strip()\n",
        "\n",
        "    def test_run(self):\n",
        "        print(\"testing\")\n",
        "        print(self.reply('Hello'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAYsvUSWgKUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    model = RikiChatBot()\n",
        "    model.test_run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOs_csYAgjCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "a61d18bf-e48b-40e1-8f58-85c0213d9394"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514\n",
            "[-0.17989   0.22297   0.47938  -0.71227  -0.45818   1.0285    0.32394\n",
            " -0.060409 -0.37064   0.3051   -0.14261  -0.56449  -4.5301    0.54817\n",
            " -0.85281  -0.086907 -0.28587   0.86288  -0.28724  -0.65113  -0.97384\n",
            "  0.11036  -0.05808  -0.034859 -0.36309   0.19478   0.17636  -0.32154\n",
            " -0.22864  -0.11961  -0.044675  0.54424  -0.25474   0.21692   0.5004\n",
            "  0.21677   0.33958  -0.27821   0.58674   0.013013 -0.98293   0.5214\n",
            "  0.11687  -0.10702   0.1903    0.25038  -0.24482  -0.068194 -0.23054\n",
            "  0.24936   0.081091 -0.71015   0.050871 -0.16209   0.49785  -0.44498\n",
            " -0.79807  -0.1008    0.80597   0.18716  -0.65218  -0.27916   0.23074\n",
            " -0.35599  -0.18894   0.36532   0.74004  -0.29412   0.90441   0.067676\n",
            " -0.19106   0.59315   0.058992  0.53448   0.32551   0.060201  0.28332\n",
            "  0.026973 -0.079146 -0.40832   1.3507   -0.1911   -0.23131  -0.37369\n",
            "  0.32181   0.10459  -0.11756   0.028256  0.27408  -0.289    -0.21644\n",
            "  0.17697  -0.23683   0.15782  -0.22889   0.26629  -0.28217   0.29003\n",
            " -0.032464 -0.55074 ]\n",
            "testing\n",
            "i 'm not going to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAtFknvScjjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f9a533e7-6802-4f29-a9cc-822df6d59a51"
      },
      "source": [
        "riki = RikiChatBot()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514\n",
            "[-0.17989   0.22297   0.47938  -0.71227  -0.45818   1.0285    0.32394\n",
            " -0.060409 -0.37064   0.3051   -0.14261  -0.56449  -4.5301    0.54817\n",
            " -0.85281  -0.086907 -0.28587   0.86288  -0.28724  -0.65113  -0.97384\n",
            "  0.11036  -0.05808  -0.034859 -0.36309   0.19478   0.17636  -0.32154\n",
            " -0.22864  -0.11961  -0.044675  0.54424  -0.25474   0.21692   0.5004\n",
            "  0.21677   0.33958  -0.27821   0.58674   0.013013 -0.98293   0.5214\n",
            "  0.11687  -0.10702   0.1903    0.25038  -0.24482  -0.068194 -0.23054\n",
            "  0.24936   0.081091 -0.71015   0.050871 -0.16209   0.49785  -0.44498\n",
            " -0.79807  -0.1008    0.80597   0.18716  -0.65218  -0.27916   0.23074\n",
            " -0.35599  -0.18894   0.36532   0.74004  -0.29412   0.90441   0.067676\n",
            " -0.19106   0.59315   0.058992  0.53448   0.32551   0.060201  0.28332\n",
            "  0.026973 -0.079146 -0.40832   1.3507   -0.1911   -0.23131  -0.37369\n",
            "  0.32181   0.10459  -0.11756   0.028256  0.27408  -0.289    -0.21644\n",
            "  0.17697  -0.23683   0.15782  -0.22889   0.26629  -0.28217   0.29003\n",
            " -0.032464 -0.55074 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enp8QlnlewwL",
        "colab_type": "text"
      },
      "source": [
        "Method 1: Predicting Manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSj2j7red65A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37e4c987-f247-4ff9-dacf-fd39819dd451"
      },
      "source": [
        "riki.reply(\"That's amazing!!!\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i do n't know . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BcknG4ue4Nt",
        "colab_type": "text"
      },
      "source": [
        "Method 2: Predicting with interactive interface (Please execute below 2 cells.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYXHAX6tX6Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chatbot_html = \"\"\"\n",
        "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
        "<div id=\"log\"\n",
        "     style=\"box-sizing: border-box;\n",
        "            width: 600px;\n",
        "            height: 32em;\n",
        "            border: 1px grey solid;\n",
        "            padding: 2px;\n",
        "            overflow: scroll;\">\n",
        "</div>\n",
        "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
        "       style=\"box-sizing: border-box;\n",
        "              width: 600px;\n",
        "              margin-top: 5px;\">\n",
        "<script>\n",
        "function paraWithText(t) {\n",
        "    let tn = document.createTextNode(t);\n",
        "    let ptag = document.createElement('p');\n",
        "    ptag.appendChild(tn);\n",
        "    return ptag;\n",
        "}\n",
        "document.querySelector('#typehere').onchange = async function() {\n",
        "    let inputField = document.querySelector('#typehere');\n",
        "    let val = inputField.value;\n",
        "    inputField.value = \"\";\n",
        "    let resp = await getResp(val);\n",
        "    let objDiv = document.getElementById(\"log\");\n",
        "    objDiv.appendChild(paraWithText(': ' + val));\n",
        "    objDiv.appendChild(paraWithText(': ' + resp));\n",
        "    objDiv.scrollTop = objDiv.scrollHeight;\n",
        "};\n",
        "async function colabGetResp(val) {\n",
        "    let resp = await google.colab.kernel.invokeFunction(\n",
        "        'notebook.get_response', [val], {});\n",
        "    return resp.data['application/json']['result'];\n",
        "}\n",
        "async function webGetResp(val) {\n",
        "    let resp = await fetch(\"/response.json?sentence=\" + \n",
        "        encodeURIComponent(val));\n",
        "    let data = await resp.json();\n",
        "    return data['result'];\n",
        "}\n",
        "</script>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9prl0CLRX9Cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "e9c9f6c1-addf-40b4-be57-a42f06d952bb"
      },
      "source": [
        " import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.HTML(chatbot_html + \\\n",
        "                             \"<script>let getResp = colabGetResp;</script>\"))\n",
        "\n",
        "def get_response(val):\n",
        "    resp = riki.reply(val)\n",
        "    return IPython.display.JSON({'result': resp})\n",
        "\n",
        "output.register_callback('notebook.get_response', get_response)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
              "<div id=\"log\"\n",
              "     style=\"box-sizing: border-box;\n",
              "            width: 600px;\n",
              "            height: 32em;\n",
              "            border: 1px grey solid;\n",
              "            padding: 2px;\n",
              "            overflow: scroll;\">\n",
              "</div>\n",
              "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
              "       style=\"box-sizing: border-box;\n",
              "              width: 600px;\n",
              "              margin-top: 5px;\">\n",
              "<script>\n",
              "function paraWithText(t) {\n",
              "    let tn = document.createTextNode(t);\n",
              "    let ptag = document.createElement('p');\n",
              "    ptag.appendChild(tn);\n",
              "    return ptag;\n",
              "}\n",
              "document.querySelector('#typehere').onchange = async function() {\n",
              "    let inputField = document.querySelector('#typehere');\n",
              "    let val = inputField.value;\n",
              "    inputField.value = \"\";\n",
              "    let resp = await getResp(val);\n",
              "    let objDiv = document.getElementById(\"log\");\n",
              "    objDiv.appendChild(paraWithText(': ' + val));\n",
              "    objDiv.appendChild(paraWithText(': ' + resp));\n",
              "    objDiv.scrollTop = objDiv.scrollHeight;\n",
              "};\n",
              "async function colabGetResp(val) {\n",
              "    let resp = await google.colab.kernel.invokeFunction(\n",
              "        'notebook.get_response', [val], {});\n",
              "    return resp.data['application/json']['result'];\n",
              "}\n",
              "async function webGetResp(val) {\n",
              "    let resp = await fetch(\"/response.json?sentence=\" + \n",
              "        encodeURIComponent(val));\n",
              "    let data = await resp.json();\n",
              "    return data['result'];\n",
              "}\n",
              "</script>\n",
              "<script>let getResp = colabGetResp;</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}